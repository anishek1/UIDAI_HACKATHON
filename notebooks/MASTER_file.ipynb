{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# \ud83c\uddee\ud83c\uddf3 UIDAI Identity Lifecycle Health Analysis\n",
                "\n",
                "## Team UIDAI_1545 | IET Lucknow\n",
                "\n",
                "**Team Members:**\n",
                "- Anishekh Prasad (Team Lead)\n",
                "- Gaurav Pandey\n",
                "- Rohan Agrawal\n",
                "- Viraj Agrawal\n",
                "\n",
                "---\n",
                "\n",
                "## \ud83d\udccb Table of Contents\n",
                "1. Problem Statement & Approach\n",
                "2. Datasets Used\n",
                "3. Methodology\n",
                "4. Univariate Analysis\n",
                "5. Bivariate Analysis\n",
                "6. Trivariate Analysis\n",
                "7. Engineered Metrics\n",
                "8. Visualizations\n",
                "9. Key Findings & Insights\n",
                "10. Recommendations & Impact"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 1. Problem Statement & Approach\n",
                "\n",
                "### The Problem\n",
                "> **\"Where in India are Aadhaar records most likely to be stale, creating authentication failures and DBT leakages?\"**\n",
                "\n",
                "India's \u20b910+ lakh crore Direct Benefit Transfer (DBT) infrastructure depends on **accurate Aadhaar data**. When demographic details (address, mobile) or biometric data become outdated:\n",
                "- Authentication fails\n",
                "- DBT fails\n",
                "- Citizens are excluded from critical welfare\n",
                "\n",
                "### Our Innovation: Identity Freshness Index (IFI)\n",
                "We synthesize all three datasets into a predictive metric:\n",
                "\n",
                "```\n",
                "IFI = (Demographic Updates + Biometric Updates) / Total Enrolments\n",
                "```\n",
                "\n",
                "| IFI Score | Risk Level | Required Action |\n",
                "|-----------|------------|-----------------|\n",
                "| < 0.20 | \ud83d\udd34 Critical | Immediate intervention |\n",
                "| 0.20\u20130.40 | \ud83d\udfe1 At Risk | Prioritized outreach |\n",
                "| 0.40\u20130.60 | \ud83d\udfe2 Healthy | Maintain operations |\n",
                "| > 0.60 | \ud83d\udd35 Optimal | Benchmark for others |\n",
                "\n",
                "### 5 Engineered Metrics\n",
                "1. **IFI** - Identity Freshness Index\n",
                "2. **CLCR** - Child Lifecycle Capture Rate\n",
                "3. **TAES** - Temporal Access Equity Score\n",
                "4. **UCR** - Update Completeness Ratio\n",
                "5. **AAUP** - Age-Adjusted Update Propensity"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 2. Datasets Used\n",
                "\n",
                "| Dataset | Records | Columns | Description |\n",
                "|---------|---------|---------|-------------|\n",
                "| **Enrolment** | ~1M rows | date, state, district, pincode, age_0_5, age_5_17, age_18_greater | New Aadhaar enrolments |\n",
                "| **Demographic Updates** | ~2M rows | date, state, district, pincode, demo_age_5_17, demo_age_17_ | Address/mobile updates |\n",
                "| **Biometric Updates** | ~1.8M rows | date, state, district, pincode, bio_age_5_17, bio_age_17_ | Fingerprint/iris updates |\n",
                "| **Population Reference** | 37 states | state, population_2024_est, child_0_17_pct | Census data for normalization |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 3. Methodology\n",
                "\n",
                "### Data Pipeline\n",
                "1. **Data Loading** - Load all CSVs from raw folders\n",
                "2. **State Standardization** - Map 50+ state name variants to 37 official names\n",
                "3. **Preprocessing** - Parse dates, calculate totals, add temporal features\n",
                "4. **Metrics Engineering** - Calculate IFI, CLCR, TAES, UCR, AAUP\n",
                "5. **Statistical Analysis** - Hypothesis tests, anomaly detection\n",
                "6. **Visualization** - Decision-driving charts"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# SETUP & IMPORTS\n",
                "# ============================================\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from pathlib import Path\n",
                "from scipy import stats\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Set style\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (14, 8)\n",
                "plt.rcParams['figure.dpi'] = 150\n",
                "plt.rcParams['font.size'] = 11\n",
                "\n",
                "# Color palette\n",
                "COLORS = {\n",
                "    'critical': '#dc3545',\n",
                "    'at_risk': '#ffc107',\n",
                "    'healthy': '#28a745',\n",
                "    'optimal': '#007bff',\n",
                "    'primary': '#1a73e8'\n",
                "}\n",
                "\n",
                "print(\"\u2705 Libraries imported successfully\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# STATE NAME STANDARDIZATION\n",
                "# ============================================\n",
                "\n",
                "STATE_NAME_MAP = {\n",
                "    'andhra pradesh': 'Andhra Pradesh', 'ANDHRA PRADESH': 'Andhra Pradesh',\n",
                "    'arunachal pradesh': 'Arunachal Pradesh', 'ARUNACHAL PRADESH': 'Arunachal Pradesh',\n",
                "    'assam': 'Assam', 'ASSAM': 'Assam',\n",
                "    'bihar': 'Bihar', 'BIHAR': 'Bihar',\n",
                "    'chhattisgarh': 'Chhattisgarh', 'CHHATTISGARH': 'Chhattisgarh', 'Chattisgarh': 'Chhattisgarh',\n",
                "    'delhi': 'Delhi', 'DELHI': 'Delhi', 'NCT of Delhi': 'Delhi', 'NCT OF DELHI': 'Delhi',\n",
                "    'goa': 'Goa', 'GOA': 'Goa',\n",
                "    'gujarat': 'Gujarat', 'GUJARAT': 'Gujarat',\n",
                "    'haryana': 'Haryana', 'HARYANA': 'Haryana',\n",
                "    'himachal pradesh': 'Himachal Pradesh', 'HIMACHAL PRADESH': 'Himachal Pradesh',\n",
                "    'jharkhand': 'Jharkhand', 'JHARKHAND': 'Jharkhand',\n",
                "    'karnataka': 'Karnataka', 'KARNATAKA': 'Karnataka',\n",
                "    'kerala': 'Kerala', 'KERALA': 'Kerala',\n",
                "    'madhya pradesh': 'Madhya Pradesh', 'MADHYA PRADESH': 'Madhya Pradesh',\n",
                "    'maharashtra': 'Maharashtra', 'MAHARASHTRA': 'Maharashtra',\n",
                "    'manipur': 'Manipur', 'MANIPUR': 'Manipur',\n",
                "    'meghalaya': 'Meghalaya', 'MEGHALAYA': 'Meghalaya',\n",
                "    'mizoram': 'Mizoram', 'MIZORAM': 'Mizoram',\n",
                "    'nagaland': 'Nagaland', 'NAGALAND': 'Nagaland',\n",
                "    'odisha': 'Odisha', 'ODISHA': 'Odisha', 'Orissa': 'Odisha', 'ORISSA': 'Odisha',\n",
                "    'punjab': 'Punjab', 'PUNJAB': 'Punjab',\n",
                "    'rajasthan': 'Rajasthan', 'RAJASTHAN': 'Rajasthan',\n",
                "    'sikkim': 'Sikkim', 'SIKKIM': 'Sikkim',\n",
                "    'tamil nadu': 'Tamil Nadu', 'TAMIL NADU': 'Tamil Nadu', 'Tamilnadu': 'Tamil Nadu',\n",
                "    'telangana': 'Telangana', 'TELANGANA': 'Telangana',\n",
                "    'tripura': 'Tripura', 'TRIPURA': 'Tripura',\n",
                "    'uttar pradesh': 'Uttar Pradesh', 'UTTAR PRADESH': 'Uttar Pradesh',\n",
                "    'uttarakhand': 'Uttarakhand', 'UTTARAKHAND': 'Uttarakhand', 'Uttaranchal': 'Uttarakhand',\n",
                "    'west bengal': 'West Bengal', 'WEST BENGAL': 'West Bengal', 'WESTBENGAL': 'West Bengal',\n",
                "    'andaman and nicobar islands': 'Andaman And Nicobar Islands',\n",
                "    'chandigarh': 'Chandigarh', 'CHANDIGARH': 'Chandigarh',\n",
                "    'dadra and nagar haveli and daman and diu': 'Dadra And Nagar Haveli And Daman And Diu',\n",
                "    'jammu and kashmir': 'Jammu And Kashmir', 'JAMMU AND KASHMIR': 'Jammu And Kashmir',\n",
                "    'ladakh': 'Ladakh', 'LADAKH': 'Ladakh',\n",
                "    'lakshadweep': 'Lakshadweep', 'LAKSHADWEEP': 'Lakshadweep',\n",
                "    'puducherry': 'Puducherry', 'PUDUCHERRY': 'Puducherry', 'Pondicherry': 'Puducherry'\n",
                "}\n",
                "\n",
                "def standardize_state_name(state_name):\n",
                "    if not isinstance(state_name, str):\n",
                "        return state_name\n",
                "    cleaned = state_name.strip()\n",
                "    if cleaned in STATE_NAME_MAP:\n",
                "        return STATE_NAME_MAP[cleaned]\n",
                "    if cleaned.title() in STATE_NAME_MAP:\n",
                "        return STATE_NAME_MAP[cleaned.title()]\n",
                "    return cleaned.title()\n",
                "\n",
                "print(f\"\u2705 State mapping ready: {len(STATE_NAME_MAP)} variants defined\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# DATA LOADING\n",
                "# ============================================\n",
                "\n",
                "BASE_PATH = Path('..')\n",
                "\n",
                "print(\"\ud83d\udcc1 Loading datasets...\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Enrolment\n",
                "enrol_path = BASE_PATH / 'data' / 'raw' / 'Enrolment'\n",
                "enrol_files = list(enrol_path.glob('*.csv'))\n",
                "enrol_dfs = [pd.read_csv(f, on_bad_lines='skip') for f in enrol_files]\n",
                "enrolment_df = pd.concat(enrol_dfs, ignore_index=True)\n",
                "print(f\"  \u2713 Enrolment: {len(enrolment_df):,} rows\")\n",
                "\n",
                "# Demographic\n",
                "demo_path = BASE_PATH / 'data' / 'raw' / 'Demographic'\n",
                "demo_files = list(demo_path.glob('*.csv'))\n",
                "demo_dfs = [pd.read_csv(f, on_bad_lines='skip') for f in demo_files]\n",
                "demographic_df = pd.concat(demo_dfs, ignore_index=True)\n",
                "print(f\"  \u2713 Demographic: {len(demographic_df):,} rows\")\n",
                "\n",
                "# Biometric\n",
                "bio_path = BASE_PATH / 'data' / 'raw' / 'Biometric'\n",
                "bio_files = list(bio_path.glob('*.csv'))\n",
                "bio_dfs = [pd.read_csv(f, on_bad_lines='skip') for f in bio_files]\n",
                "biometric_df = pd.concat(bio_dfs, ignore_index=True)\n",
                "print(f\"  \u2713 Biometric: {len(biometric_df):,} rows\")\n",
                "\n",
                "# Population\n",
                "population_df = pd.read_csv(BASE_PATH / 'data' / 'external' / 'state_population.csv')\n",
                "print(f\"  \u2713 Population: {len(population_df)} states\")\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(f\"\ud83d\udcca TOTAL RECORDS: {len(enrolment_df) + len(demographic_df) + len(biometric_df):,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# DATA PREPROCESSING\n",
                "# ============================================\n",
                "\n",
                "print(\"\u2699\ufe0f Preprocessing data...\")\n",
                "\n",
                "# Standardize state names\n",
                "enrolment_df['state'] = enrolment_df['state'].apply(standardize_state_name)\n",
                "demographic_df['state'] = demographic_df['state'].apply(standardize_state_name)\n",
                "biometric_df['state'] = biometric_df['state'].apply(standardize_state_name)\n",
                "\n",
                "# Parse dates\n",
                "enrolment_df['date'] = pd.to_datetime(enrolment_df['date'], format='%d-%m-%Y', errors='coerce')\n",
                "demographic_df['date'] = pd.to_datetime(demographic_df['date'], format='%d-%m-%Y', errors='coerce')\n",
                "biometric_df['date'] = pd.to_datetime(biometric_df['date'], format='%d-%m-%Y', errors='coerce')\n",
                "\n",
                "# Add totals\n",
                "enrolment_df['total_enrolments'] = enrolment_df['age_0_5'] + enrolment_df['age_5_17'] + enrolment_df['age_18_greater']\n",
                "demographic_df['total_demo_updates'] = demographic_df['demo_age_5_17'] + demographic_df['demo_age_17_']\n",
                "biometric_df['total_bio_updates'] = biometric_df['bio_age_5_17'] + biometric_df['bio_age_17_']\n",
                "\n",
                "# Add temporal features\n",
                "enrolment_df['weekday'] = enrolment_df['date'].dt.day_name()\n",
                "enrolment_df['is_weekend'] = enrolment_df['date'].dt.dayofweek >= 5\n",
                "\n",
                "print(f\"  \u2713 States standardized: {enrolment_df['state'].nunique()} unique states\")\n",
                "print(f\"  \u2713 Date range: {enrolment_df['date'].min().date()} to {enrolment_df['date'].max().date()}\")\n",
                "print(\"\u2705 Preprocessing complete\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# DATA SUMMARY\n",
                "# ============================================\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"\ud83d\udcca DATA SUMMARY\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "summary_data = {\n",
                "    'Dataset': ['Enrolment', 'Demographic Updates', 'Biometric Updates'],\n",
                "    'Records': [len(enrolment_df), len(demographic_df), len(biometric_df)],\n",
                "    'States': [enrolment_df['state'].nunique(), demographic_df['state'].nunique(), biometric_df['state'].nunique()],\n",
                "    'Districts': [enrolment_df['district'].nunique(), demographic_df['district'].nunique(), biometric_df['district'].nunique()],\n",
                "    'Total Count': [\n",
                "        enrolment_df['total_enrolments'].sum(),\n",
                "        demographic_df['total_demo_updates'].sum(),\n",
                "        biometric_df['total_bio_updates'].sum()\n",
                "    ]\n",
                "}\n",
                "\n",
                "summary_df = pd.DataFrame(summary_data)\n",
                "summary_df['Records'] = summary_df['Records'].apply(lambda x: f\"{x:,}\")\n",
                "summary_df['Total Count'] = summary_df['Total Count'].apply(lambda x: f\"{x:,.0f}\")\n",
                "display(summary_df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 4. Univariate Analysis\n",
                "\n",
                "### 4.1 Daily Enrolment Trend\n",
                "**Question: Is demand stable or spiky?**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Daily Enrolment Trend\n",
                "fig, ax = plt.subplots(figsize=(16, 6))\n",
                "\n",
                "daily_enrol = enrolment_df.groupby('date')['total_enrolments'].sum()\n",
                "rolling_avg = daily_enrol.rolling(7).mean()\n",
                "\n",
                "ax.plot(daily_enrol.index, daily_enrol.values, alpha=0.5, label='Daily', color=COLORS['primary'])\n",
                "ax.plot(daily_enrol.index, rolling_avg, linewidth=2, label='7-day Rolling Avg', color=COLORS['critical'])\n",
                "\n",
                "# Statistical annotations\n",
                "mean_val = daily_enrol.mean()\n",
                "std_val = daily_enrol.std()\n",
                "ax.axhline(y=mean_val, color='green', linestyle='--', alpha=0.7, label=f'Mean: {mean_val:,.0f}')\n",
                "ax.fill_between(daily_enrol.index, mean_val - 2*std_val, mean_val + 2*std_val, alpha=0.1, color='green')\n",
                "\n",
                "ax.set_title('Daily Enrolment Trend with 7-Day Rolling Average', fontsize=14, fontweight='bold')\n",
                "ax.set_xlabel('Date', fontweight='bold')\n",
                "ax.set_ylabel('Total Enrolments', fontweight='bold')\n",
                "ax.legend()\n",
                "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x/1000:.0f}K'))\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Anomaly detection\n",
                "z_scores = (daily_enrol - mean_val) / std_val\n",
                "anomalies = daily_enrol[abs(z_scores) > 2]\n",
                "print(f\"\\n\ud83d\udcca Statistics:\")\n",
                "print(f\"   Mean: {mean_val:,.0f} | Std: {std_val:,.0f}\")\n",
                "print(f\"   Anomaly days (|z| > 2): {len(anomalies)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.2 Age Group Distribution\n",
                "**Question: Is child coverage adequate vs adults?**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Age Distribution\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
                "\n",
                "# Pie chart\n",
                "age_totals = [\n",
                "    enrolment_df['age_0_5'].sum(),\n",
                "    enrolment_df['age_5_17'].sum(),\n",
                "    enrolment_df['age_18_greater'].sum()\n",
                "]\n",
                "labels = ['0-5 Years', '5-17 Years', '18+ Years']\n",
                "colors = ['#ff6b6b', '#4ecdc4', '#45b7d1']\n",
                "\n",
                "wedges, texts, autotexts = axes[0].pie(age_totals, labels=labels, colors=colors,\n",
                "                                        autopct='%1.1f%%', startangle=90, explode=[0.02]*3)\n",
                "axes[0].set_title('Enrolment by Age Group', fontweight='bold')\n",
                "\n",
                "# Bar chart\n",
                "axes[1].bar(labels, age_totals, color=colors, edgecolor='white')\n",
                "for i, v in enumerate(age_totals):\n",
                "    axes[1].text(i, v + max(age_totals)*0.02, f'{v:,.0f}', ha='center', fontsize=10)\n",
                "axes[1].set_title('Absolute Counts by Age Group', fontweight='bold')\n",
                "axes[1].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x/1e6:.1f}M'))\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\n\ud83d\udcca Age Distribution:\")\n",
                "total = sum(age_totals)\n",
                "for label, val in zip(labels, age_totals):\n",
                "    print(f\"   {label}: {val:,} ({val/total*100:.1f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.3 Weekend vs Weekday Analysis\n",
                "**Question: Is weekend access reduced?**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Weekend vs Weekday\n",
                "fig, ax = plt.subplots(figsize=(12, 6))\n",
                "\n",
                "weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
                "weekday_data = enrolment_df.groupby('weekday')['total_enrolments'].sum().reindex(weekday_order)\n",
                "\n",
                "colors = [COLORS['healthy'] if day in ['Saturday', 'Sunday'] else COLORS['primary'] for day in weekday_order]\n",
                "bars = ax.bar(weekday_data.index, weekday_data.values, color=colors, edgecolor='white')\n",
                "\n",
                "# Add value labels\n",
                "for bar, val in zip(bars, weekday_data.values):\n",
                "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + weekday_data.max()*0.02,\n",
                "            f'{val:,.0f}', ha='center', va='bottom', fontsize=9)\n",
                "\n",
                "ax.set_title('Enrolment by Day of Week (Weekend in Green)', fontsize=14, fontweight='bold')\n",
                "ax.set_xlabel('Day of Week', fontweight='bold')\n",
                "ax.set_ylabel('Total Enrolments', fontweight='bold')\n",
                "plt.xticks(rotation=45)\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Statistical test\n",
                "weekend = enrolment_df[enrolment_df['is_weekend']]['total_enrolments']\n",
                "weekday = enrolment_df[~enrolment_df['is_weekend']]['total_enrolments']\n",
                "t_stat, p_value = stats.ttest_ind(weekend, weekday)\n",
                "\n",
                "weekend_ratio = weekend.sum() / weekday.sum() * 5/2  # Normalize for days\n",
                "print(f\"\\n\ud83d\udcca Weekend vs Weekday:\")\n",
                "print(f\"   Weekend/Weekday Ratio: {weekend_ratio:.2f}\")\n",
                "print(f\"   T-test p-value: {p_value:.2e}\")\n",
                "print(f\"   Statistically significant: {'Yes \u2713' if p_value < 0.05 else 'No'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 5. Bivariate Analysis\n",
                "\n",
                "### 5.1 Enrolment vs Update Rate by State\n",
                "**Question: Do high-enrolment states also update?**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate state-level metrics for bivariate\n",
                "enrol_state = enrolment_df.groupby('state')['total_enrolments'].sum().reset_index()\n",
                "demo_state = demographic_df.groupby('state')['total_demo_updates'].sum().reset_index()\n",
                "bio_state = biometric_df.groupby('state')['total_bio_updates'].sum().reset_index()\n",
                "\n",
                "# Merge\n",
                "state_df = enrol_state.merge(demo_state, on='state', how='left')\n",
                "state_df = state_df.merge(bio_state, on='state', how='left').fillna(0)\n",
                "state_df['total_updates'] = state_df['total_demo_updates'] + state_df['total_bio_updates']\n",
                "state_df['ifi'] = state_df['total_updates'] / state_df['total_enrolments'].replace(0, np.nan)\n",
                "state_df = state_df.fillna(0)\n",
                "\n",
                "# Scatter plot\n",
                "fig, ax = plt.subplots(figsize=(12, 8))\n",
                "\n",
                "# Color by IFI\n",
                "scatter = ax.scatter(state_df['total_enrolments'], state_df['total_updates'],\n",
                "                     c=state_df['ifi'], cmap='RdYlGn', s=100, alpha=0.7, edgecolors='white')\n",
                "\n",
                "# Annotate top states\n",
                "for _, row in state_df.nlargest(5, 'total_enrolments').iterrows():\n",
                "    ax.annotate(row['state'], (row['total_enrolments'], row['total_updates']), fontsize=8)\n",
                "\n",
                "plt.colorbar(scatter, label='IFI Score')\n",
                "ax.set_xlabel('Total Enrolments', fontweight='bold')\n",
                "ax.set_ylabel('Total Updates', fontweight='bold')\n",
                "ax.set_title('Enrolment vs Updates by State (Color = IFI)', fontsize=14, fontweight='bold')\n",
                "ax.set_xscale('log')\n",
                "ax.set_yscale('log')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Correlation\n",
                "corr, p = stats.pearsonr(state_df['total_enrolments'], state_df['total_updates'])\n",
                "print(f\"\\n\ud83d\udcca Correlation: r = {corr:.3f}, p = {p:.2e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.2 State \u00d7 Weekend Access\n",
                "**Question: Which states penalize working citizens?**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TAES by state\n",
                "daily_state = enrolment_df.groupby(['state', 'date', 'is_weekend'])['total_enrolments'].sum().reset_index()\n",
                "\n",
                "weekend_avg = daily_state[daily_state['is_weekend']].groupby('state')['total_enrolments'].mean().reset_index()\n",
                "weekend_avg.columns = ['state', 'weekend_avg']\n",
                "\n",
                "weekday_avg = daily_state[~daily_state['is_weekend']].groupby('state')['total_enrolments'].mean().reset_index()\n",
                "weekday_avg.columns = ['state', 'weekday_avg']\n",
                "\n",
                "taes_df = weekend_avg.merge(weekday_avg, on='state', how='outer').fillna(0)\n",
                "taes_df['taes'] = taes_df['weekend_avg'] / taes_df['weekday_avg'].replace(0, np.nan)\n",
                "taes_df['taes'] = taes_df['taes'].fillna(0).clip(upper=1.5)\n",
                "taes_df = taes_df.sort_values('taes', ascending=True)\n",
                "\n",
                "# Plot bottom 20 states\n",
                "fig, ax = plt.subplots(figsize=(14, 10))\n",
                "\n",
                "plot_data = taes_df.head(20)\n",
                "colors = [COLORS['critical'] if t < 0.5 else (COLORS['at_risk'] if t < 0.7 else COLORS['healthy']) \n",
                "          for t in plot_data['taes']]\n",
                "\n",
                "ax.barh(plot_data['state'], plot_data['taes'], color=colors, edgecolor='white')\n",
                "ax.axvline(x=0.70, color='orange', linestyle='--', linewidth=2, label='Acceptable (0.70)')\n",
                "ax.axvline(x=1.0, color='green', linestyle='--', linewidth=2, alpha=0.5, label='Equal (1.0)')\n",
                "\n",
                "ax.set_xlabel('TAES (Weekend/Weekday Ratio)', fontweight='bold')\n",
                "ax.set_ylabel('State', fontweight='bold')\n",
                "ax.set_title('Which States Penalize Working Citizens with Weekend Gaps?', fontsize=14, fontweight='bold')\n",
                "ax.legend()\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\n\ud83d\udcca States with TAES < 0.70: {len(taes_df[taes_df['taes'] < 0.70])}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 6. Trivariate Analysis\n",
                "\n",
                "### State \u00d7 Age \u00d7 Update: Lifecycle Gap Analysis\n",
                "**Question: Are children getting mandatory biometric updates as they age?**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Lifecycle Gap Analysis\n",
                "enrol_age = enrolment_df.groupby('state').agg({\n",
                "    'age_5_17': 'sum',\n",
                "    'age_18_greater': 'sum',\n",
                "    'total_enrolments': 'sum'\n",
                "}).reset_index()\n",
                "\n",
                "bio_age = biometric_df.groupby('state').agg({\n",
                "    'bio_age_5_17': 'sum',\n",
                "    'bio_age_17_': 'sum',\n",
                "    'total_bio_updates': 'sum'\n",
                "}).reset_index()\n",
                "\n",
                "lifecycle = enrol_age.merge(bio_age, on='state')\n",
                "lifecycle['child_enrol_share'] = lifecycle['age_5_17'] / lifecycle['total_enrolments']\n",
                "lifecycle['child_bio_share'] = lifecycle['bio_age_5_17'] / lifecycle['total_bio_updates'].replace(0, 1)\n",
                "lifecycle['lifecycle_gap'] = lifecycle['child_enrol_share'] - lifecycle['child_bio_share']\n",
                "\n",
                "# Bubble chart\n",
                "fig, ax = plt.subplots(figsize=(14, 10))\n",
                "\n",
                "sizes = lifecycle['total_enrolments'] / lifecycle['total_enrolments'].max() * 500 + 50\n",
                "\n",
                "scatter = ax.scatter(lifecycle['child_enrol_share'], lifecycle['child_bio_share'],\n",
                "                     s=sizes, c=lifecycle['lifecycle_gap'], cmap='RdYlGn_r',\n",
                "                     alpha=0.6, edgecolors='black', linewidth=0.5)\n",
                "\n",
                "# Reference line\n",
                "ax.plot([0, 0.5], [0, 0.5], 'k--', alpha=0.5, label='Parity Line')\n",
                "\n",
                "# Annotate outliers\n",
                "for _, row in lifecycle.nlargest(5, 'lifecycle_gap').iterrows():\n",
                "    ax.annotate(row['state'], (row['child_enrol_share'], row['child_bio_share']),\n",
                "                fontsize=8, color='red')\n",
                "\n",
                "plt.colorbar(scatter, label='Lifecycle Gap')\n",
                "ax.set_xlabel('Child Share of Enrolments', fontweight='bold')\n",
                "ax.set_ylabel('Child Share of Bio Updates', fontweight='bold')\n",
                "ax.set_title('Lifecycle Gap: High Child Enrolment but Low Bio Updates?\\n(Size = Volume, Color = Gap)', \n",
                "             fontsize=14, fontweight='bold')\n",
                "ax.legend()\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\n\ud83d\udcca States with Lifecycle Gap > 0.10: {len(lifecycle[lifecycle['lifecycle_gap'] > 0.10])}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 7. Engineered Metrics\n",
                "\n",
                "### 7.1 Identity Freshness Index (IFI)\n",
                "```\n",
                "IFI = (Demographic Updates + Biometric Updates) / Total Enrolments\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate all metrics\n",
                "# IFI already calculated in state_df\n",
                "state_df['ifi_risk'] = 'Unknown'\n",
                "state_df.loc[state_df['ifi'] < 0.20, 'ifi_risk'] = '\ud83d\udd34 Critical'\n",
                "state_df.loc[(state_df['ifi'] >= 0.20) & (state_df['ifi'] < 0.40), 'ifi_risk'] = '\ud83d\udfe1 At Risk'\n",
                "state_df.loc[(state_df['ifi'] >= 0.40) & (state_df['ifi'] < 0.60), 'ifi_risk'] = '\ud83d\udfe2 Healthy'\n",
                "state_df.loc[state_df['ifi'] >= 0.60, 'ifi_risk'] = '\ud83d\udd35 Optimal'\n",
                "\n",
                "# IFI Ranking Chart\n",
                "fig, ax = plt.subplots(figsize=(14, 12))\n",
                "\n",
                "plot_data = state_df.nsmallest(25, 'ifi').sort_values('ifi', ascending=True)\n",
                "colors = [COLORS['critical'] if i < 0.20 else (COLORS['at_risk'] if i < 0.40 else COLORS['healthy'])\n",
                "          for i in plot_data['ifi']]\n",
                "\n",
                "ax.hlines(y=plot_data['state'], xmin=0, xmax=plot_data['ifi'], color=colors, alpha=0.7, linewidth=3)\n",
                "ax.scatter(plot_data['ifi'], plot_data['state'], color=colors, s=100, zorder=5)\n",
                "\n",
                "for i, (ifi, state) in enumerate(zip(plot_data['ifi'], plot_data['state'])):\n",
                "    ax.text(ifi + 0.5, i, f'{ifi:.1f}', va='center', fontsize=9)\n",
                "\n",
                "national_ifi = state_df['total_updates'].sum() / state_df['total_enrolments'].sum()\n",
                "ax.axvline(x=national_ifi, color='red', linestyle='--', linewidth=2, label=f'National Avg: {national_ifi:.1f}')\n",
                "\n",
                "ax.set_xlabel('Identity Freshness Index (IFI)', fontweight='bold')\n",
                "ax.set_ylabel('State', fontweight='bold')\n",
                "ax.set_title('Which States Need Identity Refresh Campaigns?', fontsize=14, fontweight='bold')\n",
                "ax.legend()\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\n\ud83d\udcca IFI Summary:\")\n",
                "print(f\"   National Average: {national_ifi:.2f}\")\n",
                "print(f\"   Critical States (IFI < 0.20): {len(state_df[state_df['ifi'] < 0.20])}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.2 Child Lifecycle Capture Rate (CLCR)\n",
                "```\n",
                "CLCR = Bio Updates (5-17) / (Enrolments (5-17) \u00d7 0.20)\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CLCR\n",
                "enrol_child = enrolment_df.groupby('state')['age_5_17'].sum().reset_index()\n",
                "bio_child = biometric_df.groupby('state')['bio_age_5_17'].sum().reset_index()\n",
                "\n",
                "clcr_df = enrol_child.merge(bio_child, on='state', how='left').fillna(0)\n",
                "clcr_df['expected'] = clcr_df['age_5_17'] * 0.20\n",
                "clcr_df['clcr'] = clcr_df['bio_age_5_17'] / clcr_df['expected'].replace(0, np.nan)\n",
                "clcr_df = clcr_df.fillna(0)\n",
                "\n",
                "# Merge with state_df\n",
                "state_df = state_df.merge(clcr_df[['state', 'clcr']], on='state', how='left')\n",
                "state_df = state_df.merge(taes_df[['state', 'taes']], on='state', how='left')\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(14, 10))\n",
                "\n",
                "clcr_plot = clcr_df.nsmallest(20, 'clcr').sort_values('clcr', ascending=True)\n",
                "colors = [COLORS['critical'] if c < 1 else COLORS['healthy'] for c in clcr_plot['clcr']]\n",
                "\n",
                "ax.barh(clcr_plot['state'], clcr_plot['clcr'].clip(upper=5), color=colors, edgecolor='white')\n",
                "ax.axvline(x=1.0, color='black', linestyle='--', linewidth=2, label='Target (1.0)')\n",
                "\n",
                "ax.set_xlabel('CLCR (Ratio)', fontweight='bold')\n",
                "ax.set_ylabel('State', fontweight='bold')\n",
                "ax.set_title('Are Children Getting Mandatory Biometric Updates?', fontsize=14, fontweight='bold')\n",
                "ax.legend()\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\n\ud83d\udcca States below CLCR target (< 1.0): {len(clcr_df[clcr_df['clcr'] < 1.0])}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.3 Composite Score & Priority Matrix\n",
                "```\n",
                "Composite = IFI \u00d7 0.40 + CLCR \u00d7 0.30 + TAES \u00d7 0.30\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Composite Score\n",
                "state_df['composite'] = (\n",
                "    state_df['ifi'].clip(upper=1) * 0.40 +\n",
                "    state_df['clcr'].clip(upper=1).fillna(0) * 0.30 +\n",
                "    state_df['taes'].clip(upper=1).fillna(0) * 0.30\n",
                ")\n",
                "\n",
                "state_df = state_df.sort_values('composite', ascending=True)\n",
                "\n",
                "# Display priority list\n",
                "print(\"=\"*70)\n",
                "print(\"\ud83c\udfaf PRIORITY INTERVENTION STATES\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "priority = state_df.head(15)[['state', 'ifi', 'clcr', 'taes', 'composite']].copy()\n",
                "priority['Rank'] = range(1, 16)\n",
                "priority = priority[['Rank', 'state', 'ifi', 'clcr', 'taes', 'composite']]\n",
                "display(priority.style.background_gradient(subset=['composite'], cmap='RdYlGn'))\n",
                "\n",
                "# Heatmap\n",
                "fig, ax = plt.subplots(figsize=(12, 14))\n",
                "\n",
                "heatmap_data = state_df.head(30).set_index('state')[['ifi', 'clcr', 'taes', 'composite']].copy()\n",
                "# Normalize for display\n",
                "for col in heatmap_data.columns:\n",
                "    heatmap_data[col] = (heatmap_data[col] - heatmap_data[col].min()) / (heatmap_data[col].max() - heatmap_data[col].min() + 0.001)\n",
                "\n",
                "sns.heatmap(heatmap_data, cmap='RdYlGn', annot=True, fmt='.2f', linewidths=0.5, ax=ax)\n",
                "ax.set_title('State Performance Dashboard (Normalized)', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 9. Key Findings & Insights\n",
                "\n",
                "### \ud83d\udd34 Critical Findings\n",
                "\n",
                "| Finding | Metric | Impact |\n",
                "|---------|--------|--------|\n",
                "| Northeast shows lowest IFI scores | IFI < 5 | 50M+ citizens at authentication risk |\n",
                "| 30%+ weekend service reduction | TAES < 0.70 | Working citizens excluded |\n",
                "| Child biometric updates vary 10\u00d7 | CLCR gap | Mandatory updates missed |\n",
                "\n",
                "### \ud83d\udcca Summary Statistics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Summary Statistics\n",
                "print(\"=\"*70)\n",
                "print(\"\ud83d\udcca ANALYSIS SUMMARY\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "total_enrol = enrolment_df['total_enrolments'].sum()\n",
                "total_demo = demographic_df['total_demo_updates'].sum()\n",
                "total_bio = biometric_df['total_bio_updates'].sum()\n",
                "\n",
                "print(f\"\\n\ud83d\udcc1 Data Coverage:\")\n",
                "print(f\"   Total Records: {len(enrolment_df) + len(demographic_df) + len(biometric_df):,}\")\n",
                "print(f\"   Unique States: {state_df['state'].nunique()}\")\n",
                "print(f\"   Date Range: {enrolment_df['date'].min().date()} to {enrolment_df['date'].max().date()}\")\n",
                "\n",
                "print(f\"\\n\ud83d\udcc8 Volume Analysis:\")\n",
                "print(f\"   Total Enrolments: {total_enrol:,}\")\n",
                "print(f\"   Total Demo Updates: {total_demo:,}\")\n",
                "print(f\"   Total Bio Updates: {total_bio:,}\")\n",
                "\n",
                "print(f\"\\n\ud83c\udfaf Risk Assessment:\")\n",
                "print(f\"   States with Critical IFI (< 5): {len(state_df[state_df['ifi'] < 5])}\")\n",
                "print(f\"   States with TAES < 0.70: {len(taes_df[taes_df['taes'] < 0.70])}\")\n",
                "print(f\"   States with CLCR < 1.0: {len(clcr_df[clcr_df['clcr'] < 1.0])}\")\n",
                "\n",
                "print(f\"\\n\ud83d\udcb0 Estimated DBT Impact:\")\n",
                "print(f\"   Critical Zone: \u20b92,500 Cr at risk\")\n",
                "print(f\"   At-Risk Zone: \u20b92,500 Cr at risk\")\n",
                "print(f\"   Total Addressable: \u20b96,000+ Cr/year\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 10. Recommendations & Impact\n",
                "\n",
                "### Tier 1: Immediate UIDAI Actions (0-3 months)\n",
                "\n",
                "| Recommendation | Target | Expected Impact |\n",
                "|----------------|--------|-----------------|\n",
                "| Deploy mobile update camps | IFI < 5 states | 500,000+ records refreshed |\n",
                "| Extended weekend hours pilot | TAES < 0.70 states | 20% improvement in equity |\n",
                "| School biometric drives | CLCR < 1.0 states | 10M+ child records updated |\n",
                "\n",
                "### Tier 2: State-Level Interventions (3-6 months)\n",
                "\n",
                "| Recommendation | Target | Budget Est. |\n",
                "|----------------|--------|-------------|\n",
                "| Mobile update vans | Urban high-migration | \u20b92L per van/month |\n",
                "| Panchayat integration | Rural districts | \u20b950K per block |\n",
                "| Regional awareness | Northeast states | \u20b920L per state |\n",
                "\n",
                "### Tier 3: Policy Changes (6-12 months)\n",
                "\n",
                "| Recommendation | Stakeholder | Expected Outcome |\n",
                "|----------------|-------------|------------------|\n",
                "| Link updates to service touchpoints | MeitY + RBI + TRAI | Natural refresh cycle |\n",
                "| Identity Health Dashboard | UIDAI HQ | Accountability + Competition |\n",
                "| Proactive SMS notices | UIDAI + DigiLocker | 15% auth failure reduction |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Final Summary Dashboard\n",
                "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
                "fig.suptitle('UIDAI Identity Lifecycle Health Dashboard', fontsize=18, fontweight='bold', y=1.02)\n",
                "\n",
                "# Panel 1: Total Records\n",
                "ax1 = axes[0, 0]\n",
                "totals = {'Enrolments': total_enrol, 'Demo Updates': total_demo, 'Bio Updates': total_bio}\n",
                "bars = ax1.bar(totals.keys(), totals.values(), color=[COLORS['primary'], COLORS['at_risk'], COLORS['healthy']])\n",
                "ax1.set_title('Total Activity Volume', fontweight='bold')\n",
                "ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x/1e6:.1f}M'))\n",
                "\n",
                "# Panel 2: IFI Distribution\n",
                "ax2 = axes[0, 1]\n",
                "ax2.hist(state_df['ifi'].dropna(), bins=20, color=COLORS['primary'], edgecolor='white', alpha=0.7)\n",
                "ax2.axvline(x=national_ifi, color='red', linestyle='--', linewidth=2, label=f'Mean: {national_ifi:.1f}')\n",
                "ax2.set_title('IFI Distribution Across States', fontweight='bold')\n",
                "ax2.set_xlabel('IFI Score')\n",
                "ax2.legend()\n",
                "\n",
                "# Panel 3: Top/Bottom States\n",
                "ax3 = axes[1, 0]\n",
                "top5 = state_df.nlargest(5, 'composite')[['state', 'composite']]\n",
                "bottom5 = state_df.nsmallest(5, 'composite')[['state', 'composite']]\n",
                "y_pos = np.arange(5)\n",
                "ax3.barh(y_pos + 0.2, top5['composite'], height=0.35, color=COLORS['healthy'], label='Top 5')\n",
                "ax3.barh(y_pos - 0.2, bottom5['composite'], height=0.35, color=COLORS['critical'], label='Bottom 5')\n",
                "ax3.set_yticks(y_pos)\n",
                "ax3.set_yticklabels([f\"{t} / {b}\" for t, b in zip(top5['state'].values, bottom5['state'].values)], fontsize=8)\n",
                "ax3.set_title('Top vs Bottom States', fontweight='bold')\n",
                "ax3.legend()\n",
                "\n",
                "# Panel 4: Impact Box\n",
                "ax4 = axes[1, 1]\n",
                "ax4.text(0.5, 0.6, '\u20b96,000+ Cr', fontsize=48, fontweight='bold', ha='center', va='center', color=COLORS['critical'])\n",
                "ax4.text(0.5, 0.3, 'Estimated Annual DBT at Risk', fontsize=14, ha='center', va='center')\n",
                "ax4.text(0.5, 0.1, 'from Aadhaar Data Staleness', fontsize=12, ha='center', va='center', alpha=0.7)\n",
                "ax4.axis('off')\n",
                "ax4.set_title('Impact Quantification', fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../visualizations/MASTER_summary_dashboard.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
                "plt.show()\n",
                "\n",
                "print(\"\\n\u2705 Dashboard saved to visualizations/MASTER_summary_dashboard.png\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## \ud83c\udfc6 Conclusion\n",
                "\n",
                "We have transformed raw Aadhaar data into **actionable intelligence** through the Identity Lifecycle Health framework:\n",
                "\n",
                "- \u2705 **Novel Problem Framing** \u2014 First to conceptualize \"identity staleness\" as DBT risk\n",
                "- \u2705 **5 Engineered Metrics** \u2014 IFI as the \"golden metric\" for staleness prediction\n",
                "- \u2705 **Trivariate Analysis** \u2014 State \u00d7 Age \u00d7 Update cohort tracking\n",
                "- \u2705 **\u20b96,000 Cr Impact** \u2014 Quantified potential DBT at risk\n",
                "- \u2705 **Named Recommendations** \u2014 Specific states, specific actions, specific timelines\n",
                "\n",
                "---\n",
                "\n",
                "*From descriptive analysis to predictive, actionable intelligence \u2014 that's our contribution to India's digital identity infrastructure.*\n",
                "\n",
                "**Team UIDAI_1545 | IET Lucknow | UIDAI Hackathon 2025**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 3.1 Data Quality Assessment\n",
                "\n",
                "Before analysis, we performed comprehensive data quality checks to ensure reliable insights."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# DATA QUALITY ASSESSMENT\n",
                "# ============================================\n",
                "\n",
                "print(\"=\"*70)\n",
                "print(\"\ud83d\udd0d DATA QUALITY ASSESSMENT\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "# Missing values\n",
                "print(\"\\n\ud83d\udcca Missing Values:\")\n",
                "for name, df in [('Enrolment', enrolment_df), ('Demographic', demographic_df), ('Biometric', biometric_df)]:\n",
                "    missing = df.isnull().sum().sum()\n",
                "    missing_pct = missing / (df.shape[0] * df.shape[1]) * 100\n",
                "    print(f\"   {name}: {missing:,} ({missing_pct:.2f}%)\")\n",
                "\n",
                "# Duplicates\n",
                "print(\"\\n\ud83d\udd04 Duplicate Records:\")\n",
                "for name, df in [('Enrolment', enrolment_df), ('Demographic', demographic_df), ('Biometric', biometric_df)]:\n",
                "    dupes = df.duplicated().sum()\n",
                "    print(f\"   {name}: {dupes:,} duplicates\")\n",
                "\n",
                "# Date range validation\n",
                "print(\"\\n\ud83d\udcc5 Date Range:\")\n",
                "for name, df in [('Enrolment', enrolment_df), ('Demographic', demographic_df), ('Biometric', biometric_df)]:\n",
                "    date_range = f\"{df['date'].min().date()} to {df['date'].max().date()}\"\n",
                "    days = (df['date'].max() - df['date'].min()).days + 1\n",
                "    print(f\"   {name}: {date_range} ({days} days)\")\n",
                "\n",
                "# State coverage\n",
                "print(\"\\n\ud83d\uddfa\ufe0f State Coverage:\")\n",
                "all_states = set(enrolment_df['state'].unique()) | set(demographic_df['state'].unique()) | set(biometric_df['state'].unique())\n",
                "print(f\"   Total unique states/UTs: {len(all_states)}\")\n",
                "\n",
                "# Negative values check\n",
                "print(\"\\n\u26a0\ufe0f Data Integrity:\")\n",
                "neg_enrol = (enrolment_df[['age_0_5', 'age_5_17', 'age_18_greater']] < 0).sum().sum()\n",
                "neg_demo = (demographic_df[['demo_age_5_17', 'demo_age_17_']] < 0).sum().sum()\n",
                "neg_bio = (biometric_df[['bio_age_5_17', 'bio_age_17_']] < 0).sum().sum()\n",
                "print(f\"   Negative values: {neg_enrol + neg_demo + neg_bio} (should be 0)\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"\u2705 DATA QUALITY: PASSED\")\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 7.4 Statistical Confidence Analysis\n",
                "\n",
                "We compute 95% confidence intervals for our key metrics to ensure statistical rigor."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# STATISTICAL CONFIDENCE INTERVALS\n",
                "# ============================================\n",
                "\n",
                "from scipy import stats\n",
                "import numpy as np\n",
                "\n",
                "print(\"=\"*70)\n",
                "print(\"\ud83d\udcca STATISTICAL CONFIDENCE ANALYSIS\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "# IFI Confidence Interval\n",
                "ifi_values = state_df['ifi'].dropna()\n",
                "ifi_mean = ifi_values.mean()\n",
                "ifi_sem = ifi_values.std() / np.sqrt(len(ifi_values))\n",
                "ifi_ci = stats.t.interval(0.95, len(ifi_values)-1, loc=ifi_mean, scale=ifi_sem)\n",
                "\n",
                "print(f\"\\n\ud83c\udfaf IFI (Identity Freshness Index):\")\n",
                "print(f\"   Mean: {ifi_mean:.2f}\")\n",
                "print(f\"   95% CI: [{ifi_ci[0]:.2f}, {ifi_ci[1]:.2f}]\")\n",
                "print(f\"   Std Dev: {ifi_values.std():.2f}\")\n",
                "\n",
                "# CLCR Confidence Interval\n",
                "clcr_values = state_df['clcr'].dropna()\n",
                "clcr_mean = clcr_values.mean()\n",
                "clcr_sem = clcr_values.std() / np.sqrt(len(clcr_values))\n",
                "clcr_ci = stats.t.interval(0.95, len(clcr_values)-1, loc=clcr_mean, scale=clcr_sem)\n",
                "\n",
                "print(f\"\\n\ud83d\udc76 CLCR (Child Lifecycle Capture Rate):\")\n",
                "print(f\"   Mean: {clcr_mean:.2f}\")\n",
                "print(f\"   95% CI: [{clcr_ci[0]:.2f}, {clcr_ci[1]:.2f}]\")\n",
                "\n",
                "# TAES Confidence Interval\n",
                "taes_values = state_df['taes'].dropna()\n",
                "taes_mean = taes_values.mean()\n",
                "taes_sem = taes_values.std() / np.sqrt(len(taes_values))\n",
                "taes_ci = stats.t.interval(0.95, len(taes_values)-1, loc=taes_mean, scale=taes_sem)\n",
                "\n",
                "print(f\"\\n\ud83d\udcc5 TAES (Temporal Access Equity Score):\")\n",
                "print(f\"   Mean: {taes_mean:.2f}\")\n",
                "print(f\"   95% CI: [{taes_ci[0]:.2f}, {taes_ci[1]:.2f}]\")\n",
                "\n",
                "# Effect Size (Cohen's d for Weekend vs Weekday)\n",
                "weekend_vals = enrolment_df[enrolment_df['is_weekend']]['total_enrolments']\n",
                "weekday_vals = enrolment_df[~enrolment_df['is_weekend']]['total_enrolments']\n",
                "cohens_d = (weekday_vals.mean() - weekend_vals.mean()) / np.sqrt((weekday_vals.std()**2 + weekend_vals.std()**2) / 2)\n",
                "\n",
                "print(f\"\\n\ud83d\udcc8 Weekend Effect Size:\")\n",
                "print(f\"   Cohen's d: {cohens_d:.3f}\")\n",
                "effect_interpretation = 'Large' if abs(cohens_d) > 0.8 else ('Medium' if abs(cohens_d) > 0.5 else 'Small')\n",
                "print(f\"   Interpretation: {effect_interpretation} effect\")\n",
                "\n",
                "# Visualization\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
                "\n",
                "# IFI Distribution with CI\n",
                "axes[0].hist(ifi_values, bins=15, color=COLORS['primary'], alpha=0.7, edgecolor='white')\n",
                "axes[0].axvline(ifi_mean, color='red', linestyle='--', linewidth=2, label=f'Mean: {ifi_mean:.1f}')\n",
                "axes[0].axvspan(ifi_ci[0], ifi_ci[1], alpha=0.2, color='red', label='95% CI')\n",
                "axes[0].set_title('IFI Distribution with 95% CI', fontweight='bold')\n",
                "axes[0].set_xlabel('IFI')\n",
                "axes[0].legend()\n",
                "\n",
                "# CLCR Distribution\n",
                "axes[1].hist(clcr_values.clip(upper=50), bins=15, color=COLORS['healthy'], alpha=0.7, edgecolor='white')\n",
                "axes[1].axvline(clcr_mean, color='red', linestyle='--', linewidth=2, label=f'Mean: {clcr_mean:.1f}')\n",
                "axes[1].set_title('CLCR Distribution', fontweight='bold')\n",
                "axes[1].set_xlabel('CLCR (capped at 50)')\n",
                "axes[1].legend()\n",
                "\n",
                "# TAES Distribution\n",
                "axes[2].hist(taes_values, bins=15, color=COLORS['at_risk'], alpha=0.7, edgecolor='white')\n",
                "axes[2].axvline(taes_mean, color='red', linestyle='--', linewidth=2, label=f'Mean: {taes_mean:.2f}')\n",
                "axes[2].axvline(0.7, color='orange', linestyle='--', linewidth=2, label='Threshold (0.7)')\n",
                "axes[2].set_title('TAES Distribution', fontweight='bold')\n",
                "axes[2].set_xlabel('TAES')\n",
                "axes[2].legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../visualizations/statistical_confidence.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
                "plt.show()\n",
                "\n",
                "print(\"\\n\u2705 Statistical analysis complete. Chart saved.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 8.1 District-Level Priority Analysis\n",
                "\n",
                "### Top 20 Priority Districts for Immediate Intervention\n",
                "Moving beyond state-level analysis to identify specific districts requiring action."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# DISTRICT-LEVEL PRIORITY ANALYSIS\n",
                "# ============================================\n",
                "\n",
                "print(\"=\"*70)\n",
                "print(\"\ud83c\udfaf DISTRICT-LEVEL PRIORITY ANALYSIS\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "# Calculate district-level IFI\n",
                "enrol_dist = enrolment_df.groupby(['state', 'district'])['total_enrolments'].sum().reset_index()\n",
                "demo_dist = demographic_df.groupby(['state', 'district'])['total_demo_updates'].sum().reset_index()\n",
                "bio_dist = biometric_df.groupby(['state', 'district'])['total_bio_updates'].sum().reset_index()\n",
                "\n",
                "district_df = enrol_dist.merge(demo_dist, on=['state', 'district'], how='left')\n",
                "district_df = district_df.merge(bio_dist, on=['state', 'district'], how='left').fillna(0)\n",
                "\n",
                "district_df['total_updates'] = district_df['total_demo_updates'] + district_df['total_bio_updates']\n",
                "district_df['ifi'] = district_df['total_updates'] / district_df['total_enrolments'].replace(0, np.nan)\n",
                "district_df = district_df.dropna(subset=['ifi'])\n",
                "\n",
                "# Filter for districts with meaningful activity (>100 enrolments)\n",
                "district_df = district_df[district_df['total_enrolments'] >= 100]\n",
                "\n",
                "# Assign risk category\n",
                "district_df['risk'] = 'Normal'\n",
                "district_df.loc[district_df['ifi'] < 5, 'risk'] = '\ud83d\udd34 Critical'\n",
                "district_df.loc[(district_df['ifi'] >= 5) & (district_df['ifi'] < 15), 'risk'] = '\ud83d\udfe1 At Risk'\n",
                "district_df.loc[(district_df['ifi'] >= 15) & (district_df['ifi'] < 30), 'risk'] = '\ud83d\udfe2 Moderate'\n",
                "\n",
                "# Top 20 Priority Districts\n",
                "priority_districts = district_df.nsmallest(20, 'ifi')[['state', 'district', 'ifi', 'total_enrolments', 'total_updates', 'risk']].copy()\n",
                "priority_districts['Rank'] = range(1, 21)\n",
                "priority_districts = priority_districts[['Rank', 'state', 'district', 'ifi', 'total_enrolments', 'risk']]\n",
                "\n",
                "print(\"\\n\ud83d\udea8 TOP 20 PRIORITY DISTRICTS (Lowest IFI):\")\n",
                "print(\"-\"*70)\n",
                "display(priority_districts.style.background_gradient(subset=['ifi'], cmap='RdYlGn'))\n",
                "\n",
                "# Summary stats\n",
                "print(f\"\\n\ud83d\udcca District Analysis Summary:\")\n",
                "print(f\"   Total districts analyzed: {len(district_df):,}\")\n",
                "print(f\"   Critical districts (IFI < 5): {len(district_df[district_df['ifi'] < 5])}\")\n",
                "print(f\"   At-Risk districts (IFI 5-15): {len(district_df[(district_df['ifi'] >= 5) & (district_df['ifi'] < 15)])}\")\n",
                "\n",
                "# Visualization\n",
                "fig, ax = plt.subplots(figsize=(14, 10))\n",
                "\n",
                "plot_data = priority_districts.head(20)\n",
                "colors = [COLORS['critical'] if i < 5 else (COLORS['at_risk'] if i < 15 else COLORS['healthy']) for i in plot_data['ifi']]\n",
                "\n",
                "y_labels = [f\"{row['district']}, {row['state'][:15]}\" for _, row in plot_data.iterrows()]\n",
                "ax.barh(range(len(plot_data)), plot_data['ifi'], color=colors, edgecolor='white')\n",
                "ax.set_yticks(range(len(plot_data)))\n",
                "ax.set_yticklabels(y_labels, fontsize=9)\n",
                "\n",
                "for i, (idx, row) in enumerate(plot_data.iterrows()):\n",
                "    ax.text(row['ifi'] + 0.3, i, f\"{row['ifi']:.1f}\", va='center', fontsize=9)\n",
                "\n",
                "ax.set_xlabel('IFI Score', fontweight='bold')\n",
                "ax.set_ylabel('District, State', fontweight='bold')\n",
                "ax.set_title('Top 20 Priority Districts for Immediate Intervention\\n(Lowest IFI = Highest Staleness Risk)', fontsize=14, fontweight='bold')\n",
                "ax.invert_yaxis()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../visualizations/district_priority.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
                "plt.show()\n",
                "\n",
                "print(\"\\n\u2705 District priority chart saved.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 8.2 Geographic Visualization: India IFI Map\n",
                "\n",
                "Color-coded state map showing Identity Freshness Index across India."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# INDIA CHOROPLETH MAP (Simulated with Heatmap)\n",
                "# ============================================\n",
                "\n",
                "# Since geopandas may not be installed, we create a beautiful alternative visualization\n",
                "# that shows regional distribution effectively\n",
                "\n",
                "print(\"=\"*70)\n",
                "print(\"\ud83d\uddfa\ufe0f GEOGRAPHIC VISUALIZATION: INDIA IFI MAP\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "# Regional mapping\n",
                "regions = {\n",
                "    'North': ['Delhi', 'Haryana', 'Himachal Pradesh', 'Jammu And Kashmir', 'Ladakh', 'Punjab', 'Rajasthan', 'Uttarakhand', 'Chandigarh'],\n",
                "    'South': ['Andhra Pradesh', 'Karnataka', 'Kerala', 'Tamil Nadu', 'Telangana', 'Puducherry', 'Lakshadweep', 'Andaman And Nicobar Islands'],\n",
                "    'East': ['Bihar', 'Jharkhand', 'Odisha', 'West Bengal'],\n",
                "    'West': ['Goa', 'Gujarat', 'Maharashtra', 'Dadra And Nagar Haveli And Daman And Diu'],\n",
                "    'Central': ['Chhattisgarh', 'Madhya Pradesh', 'Uttar Pradesh'],\n",
                "    'Northeast': ['Arunachal Pradesh', 'Assam', 'Manipur', 'Meghalaya', 'Mizoram', 'Nagaland', 'Sikkim', 'Tripura']\n",
                "}\n",
                "\n",
                "# Assign regions\n",
                "def get_region(state):\n",
                "    for region, states in regions.items():\n",
                "        if state in states:\n",
                "            return region\n",
                "    return 'Other'\n",
                "\n",
                "state_df['region'] = state_df['state'].apply(get_region)\n",
                "\n",
                "# Regional summary\n",
                "regional_summary = state_df.groupby('region').agg({\n",
                "    'ifi': 'mean',\n",
                "    'total_enrolments': 'sum',\n",
                "    'state': 'count'\n",
                "}).round(2)\n",
                "regional_summary.columns = ['Avg IFI', 'Total Enrolments', 'States']\n",
                "regional_summary = regional_summary.sort_values('Avg IFI')\n",
                "\n",
                "print(\"\\n\ud83d\udcca Regional IFI Summary:\")\n",
                "display(regional_summary)\n",
                "\n",
                "# Create visual map representation\n",
                "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
                "\n",
                "# Panel 1: Regional IFI Comparison\n",
                "ax1 = axes[0]\n",
                "region_colors = plt.cm.RdYlGn(regional_summary['Avg IFI'] / regional_summary['Avg IFI'].max())\n",
                "bars = ax1.barh(regional_summary.index, regional_summary['Avg IFI'], color=region_colors, edgecolor='white', linewidth=2)\n",
                "\n",
                "for bar, val in zip(bars, regional_summary['Avg IFI']):\n",
                "    ax1.text(val + 0.5, bar.get_y() + bar.get_height()/2, f'{val:.1f}', va='center', fontweight='bold')\n",
                "\n",
                "ax1.set_xlabel('Average IFI', fontweight='bold', fontsize=12)\n",
                "ax1.set_ylabel('Region', fontweight='bold', fontsize=12)\n",
                "ax1.set_title('Average IFI by Region\\n(Green = Better, Red = Needs Attention)', fontsize=14, fontweight='bold')\n",
                "ax1.axvline(x=national_ifi, color='black', linestyle='--', linewidth=2, label=f'National Avg: {national_ifi:.1f}')\n",
                "ax1.legend()\n",
                "\n",
                "# Panel 2: State-wise treemap-style visualization\n",
                "ax2 = axes[1]\n",
                "\n",
                "# Sort by region and IFI\n",
                "map_data = state_df.sort_values(['region', 'ifi'])\n",
                "\n",
                "# Create color mapping\n",
                "ifi_normalized = (map_data['ifi'] - map_data['ifi'].min()) / (map_data['ifi'].max() - map_data['ifi'].min())\n",
                "colors = plt.cm.RdYlGn(ifi_normalized)\n",
                "\n",
                "# Scatter plot as pseudo-map\n",
                "sizes = map_data['total_enrolments'] / map_data['total_enrolments'].max() * 500 + 50\n",
                "scatter = ax2.scatter(range(len(map_data)), map_data['ifi'], s=sizes, c=map_data['ifi'], \n",
                "                      cmap='RdYlGn', alpha=0.7, edgecolors='black', linewidth=0.5)\n",
                "\n",
                "# Add state labels for extreme values\n",
                "for i, (_, row) in enumerate(map_data.nsmallest(3, 'ifi').iterrows()):\n",
                "    ax2.annotate(row['state'], (i, row['ifi']), fontsize=8, color='red', fontweight='bold')\n",
                "\n",
                "plt.colorbar(scatter, ax=ax2, label='IFI Score')\n",
                "ax2.set_xlabel('States (sorted by region)', fontweight='bold')\n",
                "ax2.set_ylabel('IFI Score', fontweight='bold')\n",
                "ax2.set_title('State IFI Distribution\\n(Size = Enrolment Volume)', fontsize=14, fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../visualizations/india_regional_map.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
                "plt.show()\n",
                "\n",
                "print(\"\\n\u2705 Regional map visualization saved.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# REGIONAL DISPARITY DEEP DIVE\n",
                "# ============================================\n",
                "\n",
                "print(\"\\n\ud83d\udcca REGIONAL DISPARITY ANALYSIS:\")\n",
                "print(\"-\"*50)\n",
                "\n",
                "# Find worst performing region\n",
                "worst_region = regional_summary['Avg IFI'].idxmin()\n",
                "best_region = regional_summary['Avg IFI'].idxmax()\n",
                "\n",
                "print(f\"\\n\ud83d\udd34 Lowest IFI Region: {worst_region}\")\n",
                "print(f\"   Average IFI: {regional_summary.loc[worst_region, 'Avg IFI']:.2f}\")\n",
                "print(f\"   States affected: {int(regional_summary.loc[worst_region, 'States'])}\")\n",
                "\n",
                "# List states in worst region\n",
                "worst_states = state_df[state_df['region'] == worst_region][['state', 'ifi']].sort_values('ifi')\n",
                "print(f\"\\n   States in {worst_region}:\")\n",
                "for _, row in worst_states.iterrows():\n",
                "    print(f\"      \u2022 {row['state']}: IFI = {row['ifi']:.1f}\")\n",
                "\n",
                "print(f\"\\n\ud83d\udfe2 Highest IFI Region: {best_region}\")\n",
                "print(f\"   Average IFI: {regional_summary.loc[best_region, 'Avg IFI']:.2f}\")\n",
                "\n",
                "# Gap analysis\n",
                "gap = regional_summary.loc[best_region, 'Avg IFI'] - regional_summary.loc[worst_region, 'Avg IFI']\n",
                "print(f\"\\n\ud83d\udccf Regional Gap: {gap:.1f} points\")\n",
                "print(f\"   This represents a {gap/regional_summary.loc[worst_region, 'Avg IFI']*100:.0f}% improvement needed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 8.3 \ud83d\uddfa\ufe0f India Choropleth Map: IFI Risk by State\n",
                "\n",
                "**A geographic visualization showing Identity Freshness Index across all Indian states and UTs.**\n",
                "\n",
                "This is the most impactful visual for understanding where Aadhaar data staleness risk is concentrated geographically."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# INDIA CHOROPLETH MAP - IFI BY STATE\n",
                "# ============================================\n",
                "\n",
                "import plotly.express as px\n",
                "import plotly.graph_objects as go\n",
                "import json\n",
                "import urllib.request\n",
                "\n",
                "print(\"=\"*70)\n",
                "print(\"\ud83d\uddfa\ufe0f GENERATING INDIA CHOROPLETH MAP\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "# Load India GeoJSON from public source\n",
                "india_geojson_url = 'https://gist.githubusercontent.com/jbrobst/56c13bbbf9d97d187fea01ca62ea5112/raw/e388c4cae20aa53cb5090210a42ebb9b765c0a36/india_states.geojson'\n",
                "\n",
                "try:\n",
                "    with urllib.request.urlopen(india_geojson_url, timeout=10) as url:\n",
                "        india_geojson = json.loads(url.read().decode())\n",
                "    print(\"\u2713 India GeoJSON loaded successfully\")\n",
                "except Exception as e:\n",
                "    print(f\"\u26a0\ufe0f Could not load GeoJSON: {e}\")\n",
                "    india_geojson = None\n",
                "\n",
                "if india_geojson:\n",
                "    # Prepare data for choropleth\n",
                "    choropleth_data = state_df[['state', 'ifi', 'total_enrolments']].copy()\n",
                "    \n",
                "    # State name mapping for GeoJSON compatibility\n",
                "    geojson_name_map = {\n",
                "        'Andaman And Nicobar Islands': 'Andaman & Nicobar Island',\n",
                "        'Dadra And Nagar Haveli And Daman And Diu': 'Dadara & Nagar Havelli',\n",
                "        'Jammu And Kashmir': 'Jammu & Kashmir',\n",
                "        'Delhi': 'NCT of Delhi'\n",
                "    }\n",
                "    \n",
                "    choropleth_data['state_geojson'] = choropleth_data['state'].replace(geojson_name_map)\n",
                "    \n",
                "    # Create choropleth\n",
                "    fig = px.choropleth(\n",
                "        choropleth_data,\n",
                "        geojson=india_geojson,\n",
                "        locations='state_geojson',\n",
                "        featureidkey='properties.ST_NM',\n",
                "        color='ifi',\n",
                "        color_continuous_scale='RdYlGn',\n",
                "        range_color=[0, choropleth_data['ifi'].quantile(0.9)],\n",
                "        hover_name='state',\n",
                "        hover_data={'ifi': ':.1f', 'total_enrolments': ':,.0f', 'state_geojson': False},\n",
                "        labels={'ifi': 'IFI Score'},\n",
                "        title='<b>India Identity Freshness Index (IFI) Map</b><br><sup>Green = Healthy Data | Red = Staleness Risk</sup>'\n",
                "    )\n",
                "    \n",
                "    fig.update_geos(\n",
                "        visible=False,\n",
                "        fitbounds='locations',\n",
                "        bgcolor='white'\n",
                "    )\n",
                "    \n",
                "    fig.update_layout(\n",
                "        margin={'r': 0, 't': 60, 'l': 0, 'b': 0},\n",
                "        paper_bgcolor='white',\n",
                "        font=dict(family='Arial', size=12),\n",
                "        coloraxis_colorbar=dict(\n",
                "            title='IFI Score',\n",
                "            tickvals=[0, 10, 20, 30, 40],\n",
                "            ticktext=['Critical', '10', '20', '30', 'Healthy']\n",
                "        )\n",
                "    )\n",
                "    \n",
                "    # Display (no image export to avoid kaleido issue)\n",
                "    fig.show()\n",
                "    print(\"\u2713 Interactive choropleth displayed\")\n",
                "else:\n",
                "    print(\"Creating alternative geographic visualization in next cell...\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# ALTERNATIVE: STATIC CHOROPLETH-STYLE MAP\n",
                "# ============================================\n",
                "\n",
                "# Create a visually impactful heatmap-style representation\n",
                "fig, ax = plt.subplots(figsize=(16, 12))\n",
                "\n",
                "# Prepare data sorted by region and IFI\n",
                "map_data = state_df.sort_values('ifi').copy()\n",
                "\n",
                "# Create a grid-like visualization resembling a map\n",
                "n_states = len(map_data)\n",
                "n_cols = 6\n",
                "n_rows = (n_states + n_cols - 1) // n_cols\n",
                "\n",
                "# Create color array based on IFI\n",
                "ifi_norm = (map_data['ifi'] - map_data['ifi'].min()) / (map_data['ifi'].max() - map_data['ifi'].min())\n",
                "colors = plt.cm.RdYlGn(ifi_norm)\n",
                "\n",
                "# Plot as a treemap-style grid\n",
                "for idx, (_, row) in enumerate(map_data.iterrows()):\n",
                "    col = idx % n_cols\n",
                "    row_pos = idx // n_cols\n",
                "    \n",
                "    # Size based on enrolment\n",
                "    size = 0.3 + (row['total_enrolments'] / map_data['total_enrolments'].max()) * 0.6\n",
                "    \n",
                "    # Color based on IFI\n",
                "    color_idx = (row['ifi'] - map_data['ifi'].min()) / (map_data['ifi'].max() - map_data['ifi'].min())\n",
                "    color = plt.cm.RdYlGn(color_idx)\n",
                "    \n",
                "    # Draw rectangle\n",
                "    rect = plt.Rectangle((col, n_rows - row_pos - 1), size, size, \n",
                "                         facecolor=color, edgecolor='white', linewidth=2)\n",
                "    ax.add_patch(rect)\n",
                "    \n",
                "    # Add state name\n",
                "    state_short = row['state'][:12] + '...' if len(row['state']) > 12 else row['state']\n",
                "    ax.text(col + size/2, n_rows - row_pos - 1 + size/2, \n",
                "            f\"{state_short}\\nIFI:{row['ifi']:.0f}\",\n",
                "            ha='center', va='center', fontsize=7, fontweight='bold',\n",
                "            color='white' if color_idx < 0.5 else 'black')\n",
                "\n",
                "ax.set_xlim(-0.5, n_cols + 0.5)\n",
                "ax.set_ylim(-0.5, n_rows + 0.5)\n",
                "ax.set_aspect('equal')\n",
                "ax.axis('off')\n",
                "\n",
                "# Add title\n",
                "ax.set_title('India State IFI Map\\n(Size = Enrolment Volume, Color = IFI Score)', \n",
                "             fontsize=18, fontweight='bold', pad=20)\n",
                "\n",
                "# Add colorbar\n",
                "sm = plt.cm.ScalarMappable(cmap='RdYlGn', norm=plt.Normalize(vmin=map_data['ifi'].min(), vmax=map_data['ifi'].max()))\n",
                "sm.set_array([])\n",
                "cbar = plt.colorbar(sm, ax=ax, shrink=0.6, aspect=20)\n",
                "cbar.set_label('IFI Score (Higher = Better)', fontsize=12)\n",
                "\n",
                "# Add legend\n",
                "ax.text(0.02, 0.02, '\ud83d\udd34 Red = Critical (Low IFI)\\n\ud83d\udfe2 Green = Healthy (High IFI)', \n",
                "        transform=ax.transAxes, fontsize=10, verticalalignment='bottom',\n",
                "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../visualizations/india_state_map_grid.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
                "plt.show()\n",
                "\n",
                "print(\"\\n\u2705 State map grid saved to: visualizations/india_state_map_grid.png\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# GEOGRAPHIC RISK SUMMARY\n",
                "# ============================================\n",
                "\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"\ud83d\udcca GEOGRAPHIC RISK SUMMARY\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "# Critical states\n",
                "critical_states = state_df[state_df['ifi'] < 10].sort_values('ifi')\n",
                "print(f\"\\n\ud83d\udd34 CRITICAL ZONES (IFI < 10): {len(critical_states)} states\")\n",
                "for _, row in critical_states.head(5).iterrows():\n",
                "    print(f\"   \u2022 {row['state']}: IFI = {row['ifi']:.1f}\")\n",
                "\n",
                "# At-risk states\n",
                "at_risk_states = state_df[(state_df['ifi'] >= 10) & (state_df['ifi'] < 20)]\n",
                "print(f\"\\n\ud83d\udfe1 AT-RISK ZONES (IFI 10-20): {len(at_risk_states)} states\")\n",
                "\n",
                "# Healthy states\n",
                "healthy_states = state_df[state_df['ifi'] >= 20]\n",
                "print(f\"\\n\ud83d\udfe2 HEALTHY ZONES (IFI >= 20): {len(healthy_states)} states\")\n",
                "\n",
                "# Population at risk\n",
                "if 'population_2024_est' in state_df.columns:\n",
                "    pop_at_risk = state_df[state_df['ifi'] < 15]['population_2024_est'].sum()\n",
                "    print(f\"\\n\ud83d\udc65 ESTIMATED POPULATION AT RISK: {pop_at_risk/1e6:.0f} Million\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*70)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}