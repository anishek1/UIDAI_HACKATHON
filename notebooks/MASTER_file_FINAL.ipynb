{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h1 { font-size: 2.5em !important; color: #2c3e50 !important; border-bottom: 2px solid #e74c3c !important; padding-bottom: 10px; }\n",
    "    h2 { font-size: 2.0em !important; color: #34495e !important; margin-top: 40px !important; }\n",
    "    h3 { font-size: 1.5em !important; color: #7f8c8d !important; }\n",
    "    .alert-box { background-color: #f1f8ff; border-left: 5px solid #0366d6; padding: 15px; margin: 20px 0; }\n",
    "    .metric-box { background-color: #fcf8e3; border: 1px solid #faebcc; padding: 15px; border-radius: 5px; text-align: center; }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üáÆüá≥ UIDAI Identity Lifecycle Health Analysis\n",
    "\n",
    "## Team UIDAI_1545 | IET Lucknow\n",
    "\n",
    "**Team Members:**\n",
    "- Anishekh Prasad (Team Lead)\n",
    "- Gaurav Pandey\n",
    "- Rohan Agrawal\n",
    "- Viraj Agrawal\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Table of Contents\n",
    "1. Problem Statement & Approach\n",
    "2. Datasets Used\n",
    "3. Methodology\n",
    "4. Univariate Analysis\n",
    "5. Bivariate Analysis\n",
    "6. Trivariate Analysis\n",
    "7. Engineered Metrics\n",
    "8. Visualizations\n",
    "9. Key Findings & Insights\n",
    "10. Recommendations & Impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìë Table of Contents\n",
    "\n",
    "| Section | Page Content |\n",
    "|:---|:---|\n",
    "| **1. Executive Brief** | Project Drishti, Hero Metrics, & The Verdict |\n",
    "| **2. Problem Statement** | The 'Identity Staleness' Crisis |\n",
    "| **3. Datasets Used** | Enrolment, Demographic, & Biometric Data Sources |\n",
    "| **4. Methodology** | Pipeline Architecture & The IFI Formula |\n",
    "| **5. Analysis & Findings** | Regional, Lifecycle, & Temporal Insights |\n",
    "| **6. Visual Evidence** | Maps, Priority Matrices, & Trends |\n",
    "| **7. Recommendations** | 3-Tiered Strategy & Financial Impact |\n",
    "| **Appendix** | Code & Technical Implementation |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "## 1. The Challenge: Why \"Freshness\" Matters\n",
    "\n",
    "\n",
    "\n",
    "Most analysis focuses on *growth* (e.g., \"How many new enrolments?\"). We argue that since Aadhaar has >99% saturation, the real metric of success is now **Maintenance**.\n",
    "\n",
    "\n",
    "\n",
    "### üîç The Core Question\n",
    "\n",
    "If a citizen enrolled 10 years ago and hasn't updated their data since, can we rely on that identity today? \n",
    "\n",
    "\n",
    "\n",
    "> **Our Hypothesis:** Stale data leads to authentication failures. By identifying *where* data is stale, we can prevent those failures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "## 2. The Evidence Base\n",
    "\n",
    "\n",
    "\n",
    "We utilized three primary datasets provided by UIDAI. Instead of treating them in isolation, we linked them to build a comprehensive view of the lifecycle.\n",
    "\n",
    "\n",
    "\n",
    "| Dataset | What it Tells Us | Key Columns |\n",
    "\n",
    "|:---|:---|:---|\n",
    "\n",
    "| **Enrolment** | The Baseline Volume | `date`, `state`, `district`, `age_group` |\n",
    "\n",
    "| **Demographic** | The \"Soft\" Updates | `mobile_update`, `address_change` |\n",
    "\n",
    "| **Biometric** | The Critical Updates | `mandatory_biometric_update` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "## 3. Our Approach: From Raw Logs to Risk Scores\n",
    "\n",
    "\n",
    "\n",
    "We didn't just count rows. We engineered a robust pipeline to measure health.\n",
    "\n",
    "\n",
    "\n",
    "### üèóÔ∏è The 3-Step Pipeline\n",
    "\n",
    "1.  **Standardization:** Mapping 50+ state name variations (e.g., \"Telengana\" vs \"Telangana\") to a single canonical list.\n",
    "\n",
    "2.  **Transformation:** Aggregating daily logs into monthly/yearly trends and flagging weekends.\n",
    "\n",
    "3.  **Metric Engineering:** Creating the **IFI Score**.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "# The Project Drishti Formula\n",
    "\n",
    "IFI = (Demographic_Updates + Biometric_Updates) / Total_Enrolments\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SETUP & IMPORTS\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# VISUALIZATION STYLING\n",
    "# ---------------------------------------------------------\n",
    "# Set professional style for government/consulting reports\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Global Figure Settings\n",
    "plt.rcParams['figure.figsize'] = (16, 10)  # Larger, presentation-ready\n",
    "plt.rcParams['figure.dpi'] = 150           # High resolution\n",
    "plt.rcParams['figure.titlesize'] = 20      # Main title size\n",
    "plt.rcParams['figure.titleweight'] = 'bold'\n",
    "\n",
    "# Axes Settings\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['axes.titleweight'] = 'bold'\n",
    "plt.rcParams['axes.labelsize'] = 13\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "\n",
    "# Tick Settings\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Legend Settings\n",
    "plt.rcParams['legend.fontsize'] = 12\n",
    "plt.rcParams['legend.frameon'] = True\n",
    "plt.rcParams['legend.framealpha'] = 0.95\n",
    "plt.rcParams['legend.facecolor'] = 'white'\n",
    "plt.rcParams['legend.edgecolor'] = '#dbdbdb'\n",
    "\n",
    "# Font Family (clean, sans-serif)\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans', 'Liberation Sans', 'Bitstream Vera Sans', 'sans-serif']\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# COLOR PALETTE\n",
    "# ---------------------------------------------------------\n",
    "# Consistent, high-contrast palette\n",
    "COLORS = {\n",
    "    'critical': '#d32f2f',   # Strong Red\n",
    "    'at_risk': '#fbc02d',    # Warning Yellow/Amber\n",
    "    'healthy': '#388e3c',    # Strong Green\n",
    "    'optimal': '#1976d2',    # Primary Blue\n",
    "    'primary': '#1565c0',    # Deep Blue\n",
    "    'secondary': '#546e7a',  # Blue Grey\n",
    "    'neutral': '#9e9e9e',    # Grey\n",
    "    'text_main': '#212121',  # Almost Black\n",
    "    'background': '#ffffff'  # White\n",
    "}\n",
    "\n",
    "# Custom Color Maps\n",
    "cmap_risk = mcolors.LinearSegmentedColormap.from_list(\"risk\", [COLORS['healthy'], COLORS['at_risk'], COLORS['critical']])\n",
    "cmap_performance = mcolors.LinearSegmentedColormap.from_list(\"perf\", [COLORS['critical'], COLORS['at_risk'], COLORS['healthy'], COLORS['optimal']])\n",
    "\n",
    "print(\"‚úÖ Visualization standards applied successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STATE NAME STANDARDIZATION\n",
    "# ============================================\n",
    "\n",
    "STATE_NAME_MAP = {\n",
    "    'andhra pradesh': 'Andhra Pradesh', 'ANDHRA PRADESH': 'Andhra Pradesh',\n",
    "    'arunachal pradesh': 'Arunachal Pradesh', 'ARUNACHAL PRADESH': 'Arunachal Pradesh',\n",
    "    'assam': 'Assam', 'ASSAM': 'Assam',\n",
    "    'bihar': 'Bihar', 'BIHAR': 'Bihar',\n",
    "    'chhattisgarh': 'Chhattisgarh', 'CHHATTISGARH': 'Chhattisgarh', 'Chattisgarh': 'Chhattisgarh',\n",
    "    'delhi': 'Delhi', 'DELHI': 'Delhi', 'NCT of Delhi': 'Delhi', 'NCT OF DELHI': 'Delhi',\n",
    "    'goa': 'Goa', 'GOA': 'Goa',\n",
    "    'gujarat': 'Gujarat', 'GUJARAT': 'Gujarat',\n",
    "    'haryana': 'Haryana', 'HARYANA': 'Haryana',\n",
    "    'himachal pradesh': 'Himachal Pradesh', 'HIMACHAL PRADESH': 'Himachal Pradesh',\n",
    "    'jharkhand': 'Jharkhand', 'JHARKHAND': 'Jharkhand',\n",
    "    'karnataka': 'Karnataka', 'KARNATAKA': 'Karnataka',\n",
    "    'kerala': 'Kerala', 'KERALA': 'Kerala',\n",
    "    'madhya pradesh': 'Madhya Pradesh', 'MADHYA PRADESH': 'Madhya Pradesh',\n",
    "    'maharashtra': 'Maharashtra', 'MAHARASHTRA': 'Maharashtra',\n",
    "    'manipur': 'Manipur', 'MANIPUR': 'Manipur',\n",
    "    'meghalaya': 'Meghalaya', 'MEGHALAYA': 'Meghalaya',\n",
    "    'mizoram': 'Mizoram', 'MIZORAM': 'Mizoram',\n",
    "    'nagaland': 'Nagaland', 'NAGALAND': 'Nagaland',\n",
    "    'odisha': 'Odisha', 'ODISHA': 'Odisha', 'Orissa': 'Odisha', 'ORISSA': 'Odisha',\n",
    "    'punjab': 'Punjab', 'PUNJAB': 'Punjab',\n",
    "    'rajasthan': 'Rajasthan', 'RAJASTHAN': 'Rajasthan',\n",
    "    'sikkim': 'Sikkim', 'SIKKIM': 'Sikkim',\n",
    "    'tamil nadu': 'Tamil Nadu', 'TAMIL NADU': 'Tamil Nadu', 'Tamilnadu': 'Tamil Nadu',\n",
    "    'telangana': 'Telangana', 'TELANGANA': 'Telangana',\n",
    "    'tripura': 'Tripura', 'TRIPURA': 'Tripura',\n",
    "    'uttar pradesh': 'Uttar Pradesh', 'UTTAR PRADESH': 'Uttar Pradesh',\n",
    "    'uttarakhand': 'Uttarakhand', 'UTTARAKHAND': 'Uttarakhand', 'Uttaranchal': 'Uttarakhand',\n",
    "    'west bengal': 'West Bengal', 'WEST BENGAL': 'West Bengal', 'WESTBENGAL': 'West Bengal',\n",
    "    'andaman and nicobar islands': 'Andaman And Nicobar Islands',\n",
    "    'chandigarh': 'Chandigarh', 'CHANDIGARH': 'Chandigarh',\n",
    "    'dadra and nagar haveli and daman and diu': 'Dadra And Nagar Haveli And Daman And Diu',\n",
    "    'jammu and kashmir': 'Jammu And Kashmir', 'JAMMU AND KASHMIR': 'Jammu And Kashmir',\n",
    "    'ladakh': 'Ladakh', 'LADAKH': 'Ladakh',\n",
    "    'lakshadweep': 'Lakshadweep', 'LAKSHADWEEP': 'Lakshadweep',\n",
    "    'puducherry': 'Puducherry', 'PUDUCHERRY': 'Puducherry', 'Pondicherry': 'Puducherry'\n",
    "}\n",
    "\n",
    "def standardize_state_name(state_name):\n",
    "    if not isinstance(state_name, str):\n",
    "        return state_name\n",
    "    cleaned = state_name.strip()\n",
    "    if cleaned in STATE_NAME_MAP:\n",
    "        return STATE_NAME_MAP[cleaned]\n",
    "    if cleaned.title() in STATE_NAME_MAP:\n",
    "        return STATE_NAME_MAP[cleaned.title()]\n",
    "    return cleaned.title()\n",
    "\n",
    "print(f\"‚úÖ State mapping ready: {len(STATE_NAME_MAP)} variants defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DATA LOADING\n",
    "# ============================================\n",
    "\n",
    "BASE_PATH = Path('..')\n",
    "\n",
    "print(\"üìÅ Loading datasets...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Enrolment\n",
    "enrol_path = BASE_PATH / 'data' / 'raw' / 'Enrolment'\n",
    "enrol_files = list(enrol_path.glob('*.csv'))\n",
    "enrol_dfs = [pd.read_csv(f, on_bad_lines='skip') for f in enrol_files]\n",
    "enrolment_df = pd.concat(enrol_dfs, ignore_index=True)\n",
    "print(f\"  ‚úì Enrolment: {len(enrolment_df):,} rows\")\n",
    "\n",
    "# Demographic\n",
    "demo_path = BASE_PATH / 'data' / 'raw' / 'Demographic'\n",
    "demo_files = list(demo_path.glob('*.csv'))\n",
    "demo_dfs = [pd.read_csv(f, on_bad_lines='skip') for f in demo_files]\n",
    "demographic_df = pd.concat(demo_dfs, ignore_index=True)\n",
    "print(f\"  ‚úì Demographic: {len(demographic_df):,} rows\")\n",
    "\n",
    "# Biometric\n",
    "bio_path = BASE_PATH / 'data' / 'raw' / 'Biometric'\n",
    "bio_files = list(bio_path.glob('*.csv'))\n",
    "bio_dfs = [pd.read_csv(f, on_bad_lines='skip') for f in bio_files]\n",
    "biometric_df = pd.concat(bio_dfs, ignore_index=True)\n",
    "print(f\"  ‚úì Biometric: {len(biometric_df):,} rows\")\n",
    "\n",
    "# Population\n",
    "population_df = pd.read_csv(BASE_PATH / 'data' / 'external' / 'state_population.csv')\n",
    "print(f\"  ‚úì Population: {len(population_df)} states\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"üìä TOTAL RECORDS: {len(enrolment_df) + len(demographic_df) + len(biometric_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DATA PREPROCESSING\n",
    "# ============================================\n",
    "\n",
    "print(\"‚öôÔ∏è Preprocessing data...\")\n",
    "\n",
    "# Standardize state names\n",
    "enrolment_df['state'] = enrolment_df['state'].apply(standardize_state_name)\n",
    "demographic_df['state'] = demographic_df['state'].apply(standardize_state_name)\n",
    "biometric_df['state'] = biometric_df['state'].apply(standardize_state_name)\n",
    "\n",
    "# Parse dates\n",
    "enrolment_df['date'] = pd.to_datetime(enrolment_df['date'], format='%d-%m-%Y', errors='coerce')\n",
    "demographic_df['date'] = pd.to_datetime(demographic_df['date'], format='%d-%m-%Y', errors='coerce')\n",
    "biometric_df['date'] = pd.to_datetime(biometric_df['date'], format='%d-%m-%Y', errors='coerce')\n",
    "\n",
    "# Add totals\n",
    "enrolment_df['total_enrolments'] = enrolment_df['age_0_5'] + enrolment_df['age_5_17'] + enrolment_df['age_18_greater']\n",
    "demographic_df['total_demo_updates'] = demographic_df['demo_age_5_17'] + demographic_df['demo_age_17_']\n",
    "biometric_df['total_bio_updates'] = biometric_df['bio_age_5_17'] + biometric_df['bio_age_17_']\n",
    "\n",
    "# Add temporal features\n",
    "enrolment_df['weekday'] = enrolment_df['date'].dt.day_name()\n",
    "enrolment_df['is_weekend'] = enrolment_df['date'].dt.dayofweek >= 5\n",
    "\n",
    "print(f\"  ‚úì States standardized: {enrolment_df['state'].nunique()} unique states\")\n",
    "print(f\"  ‚úì Date range: {enrolment_df['date'].min().date()} to {enrolment_df['date'].max().date()}\")\n",
    "print(\"‚úÖ Preprocessing complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DATA SUMMARY\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üìä DATA SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "summary_data = {\n",
    "    'Dataset': ['Enrolment', 'Demographic Updates', 'Biometric Updates'],\n",
    "    'Records': [len(enrolment_df), len(demographic_df), len(biometric_df)],\n",
    "    'States': [enrolment_df['state'].nunique(), demographic_df['state'].nunique(), biometric_df['state'].nunique()],\n",
    "    'Districts': [enrolment_df['district'].nunique(), demographic_df['district'].nunique(), biometric_df['district'].nunique()],\n",
    "    'Total Count': [\n",
    "        enrolment_df['total_enrolments'].sum(),\n",
    "        demographic_df['total_demo_updates'].sum(),\n",
    "        biometric_df['total_bio_updates'].sum()\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df['Records'] = summary_df['Records'].apply(lambda x: f\"{x:,}\")\n",
    "summary_df['Total Count'] = summary_df['Total Count'].apply(lambda x: f\"{x:,.0f}\")\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "## 4. üìâ Insight 1: The 'Weekend Gap' in Access\n",
    "\n",
    "\n",
    "\n",
    "When we analyze the daily heartbeat of enrolments, a clear pattern emerges. The dips aren't random errors‚Äîthey are Sundays.\n",
    "\n",
    "\n",
    "\n",
    "> **üí° Why this matters:** Working-class citizens often cannot afford to take a day off work (Mon-Fri) to visit a Kendra. If services are offline on weekends, we are effectively excluding them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insight 1: DAILY ENROLMENT TREND\n",
    "# ============================================\n",
    "# Insight: Visualizing the 'Weekend Gap' in enrolment efficiency.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "daily_enrol = enrolment_df.groupby('date')['total_enrolments'].sum()\n",
    "rolling_avg = daily_enrol.rolling(7).mean()\n",
    "\n",
    "# 1. Plot Data\n",
    "ax.plot(daily_enrol.index, daily_enrol.values, alpha=0.4, color=COLORS['secondary'], label='Daily Volume', linewidth=1)\n",
    "ax.plot(daily_enrol.index, rolling_avg, linewidth=3, color=COLORS['primary'], label='7-Day Rolling Average')\n",
    "\n",
    "# 2. Statistical Annotations\n",
    "mean_val = daily_enrol.mean()\n",
    "ax.axhline(y=mean_val, color=COLORS['healthy'], linestyle='--', linewidth=2, label=f'Period Mean: {mean_val:,.0f}')\n",
    "\n",
    "# Highlight Weekends\n",
    "ax.annotate('Regular Weekend Dips', xy=(mdates.date2num(daily_enrol.index[13]), daily_enrol.values[13]), \n",
    "            xytext=(mdates.date2num(daily_enrol.index[25]), daily_enrol.values[13] + 5000),\n",
    "            arrowprops=dict(facecolor=COLORS['text_main'], shrink=0.05), fontsize=12, fontweight='bold')\n",
    "\n",
    "# 3. Formatting\n",
    "ax.set_title('Daily Enrolment Consistency: The \"Weekend Gap\" Phenomenon', pad=20)\n",
    "ax.set_xlabel('Timeline (2025)', labelpad=10)\n",
    "ax.set_ylabel('Total Daily Enrolments', labelpad=10)\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, p: f'{x/1000:.0f}K'))\n",
    "ax.grid(True, linestyle=':', alpha=0.6)\n",
    "ax.legend(loc='upper right', frameon=True, shadow=True)\n",
    "\n",
    "# 4. Insight Text\n",
    "plt.figtext(0.5, -0.05, \"Insight: Consistent dips every 7 days indicate significant drop in service availability on weekends, potentially excluding working-class citizens.\", \n",
    "            ha='center', fontsize=12, style='italic', bbox={'facecolor': '#f5f5f5', 'alpha': 0.5, 'pad': 10})\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Anomaly stats\n",
    "z_scores = (daily_enrol - mean_val) / daily_enrol.std()\n",
    "print(f\"Stats: Mean={mean_val:,.0f}, Anomalies={len(daily_enrol[abs(z_scores)>2])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Age Group Distribution\n",
    "**Question: Is child coverage adequate vs adults?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insight 2: DEMOGRAPHIC COMPOSITION\n",
    "# ============================================\n",
    "# Insight: Who are we enrolling?\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Data Prep\n",
    "age_totals = [\n",
    "    enrolment_df['age_0_5'].sum(),\n",
    "    enrolment_df['age_5_17'].sum(),\n",
    "    enrolment_df['age_18_greater'].sum()\n",
    "]\n",
    "labels = ['0-5 Years (Child)', '5-17 Years (Student)', '18+ Years (Adult)']\n",
    "colors = [COLORS['at_risk'], COLORS['optimal'], COLORS['primary']]\n",
    "\n",
    "# 1. Pie Chart (Donut)\n",
    "wedges, texts, autotexts = axes[0].pie(age_totals, labels=labels, colors=colors,\n",
    "                                        autopct='%1.1f%%', startangle=90, pctdistance=0.85, \n",
    "                                        wedgeprops=dict(width=0.5, edgecolor='white'))\n",
    "for t in texts: t.set_fontsize(11)\n",
    "for t in autotexts: t.set_fontsize(11); t.set_fontweight('bold'); t.set_color('white')\n",
    "\n",
    "axes[0].set_title('Share of Total Enrolments', pad=15)\n",
    "axes[0].text(0, 0, f\"Total\\n{sum(age_totals)/1e6:.1f}M\", ha='center', va='center', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 2. Bar Chart\n",
    "bar_x = np.arange(len(labels))\n",
    "bars = axes[1].bar(bar_x, age_totals, color=colors, edgecolor='white', width=0.6)\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2., height + 0.01*max(age_totals),\n",
    "            f'{height/1e6:.1f} M', ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "axes[1].set_title('Absolute Volume by Age Segment', pad=15)\n",
    "axes[1].set_xticks(bar_x)\n",
    "axes[1].set_xticklabels(labels)\n",
    "axes[1].set_ylabel('Enrolments (Millions)')\n",
    "axes[1].yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, p: f'{x/1e6:.1f}M'))\n",
    "axes[1].grid(axis='y', linestyle=':', alpha=0.6)\n",
    "\n",
    "plt.suptitle('Enrolment Demographics: Focus on Youth', fontsize=22, y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Weekend vs Weekday Analysis\n",
    "**Question: Is weekend access reduced?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insight 3: WEEKEND ACCESSIBILITY GAP\n",
    "# ============================================\n",
    "# Insight: Quantifying the service drop-off on weekends.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "weekday_data = enrolment_df.groupby('weekday')['total_enrolments'].sum().reindex(weekday_order)\n",
    "\n",
    "# Conditional Coloring\n",
    "colors_week = [COLORS['healthy'] if day in ['Saturday', 'Sunday'] else COLORS['primary'] for day in weekday_order]\n",
    "\n",
    "bars = ax.bar(weekday_data.index, weekday_data.values, color=colors_week, edgecolor='white', width=0.7)\n",
    "\n",
    "# Annotation of the Gap\n",
    "avg_weekday = weekday_data[:5].mean()\n",
    "avg_weekend = weekday_data[5:].mean()\n",
    "gap_pct = (avg_weekend - avg_weekday) / avg_weekday * 100\n",
    "\n",
    "ax.axhline(y=avg_weekday, color=COLORS['primary'], linestyle='--', alpha=0.5, label='Avg Weekday Volume')\n",
    "ax.axhline(y=avg_weekend, color=COLORS['healthy'], linestyle='--', alpha=0.5, label='Avg Weekend Volume')\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.02*max(weekday_data.values),\n",
    "            f'{height/1000:.0f}K', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "arrow_x = 5.5 # Between Sat/Sun\n",
    "ax.annotate(f'{gap_pct:.1f}% Drop', \n",
    "            xy=(arrow_x, avg_weekend), xytext=(arrow_x, avg_weekday),\n",
    "            arrowprops=dict(arrowstyle='<->', color=COLORS['critical'], lw=2),\n",
    "            ha='center', va='center', fontweight='bold', color=COLORS['critical'], backgroundcolor='white')\n",
    "\n",
    "ax.set_title('Service Accessibility: Significant Drop-off on Weekends', pad=20)\n",
    "ax.set_ylabel('Total Enrolments')\n",
    "ax.set_xlabel('')\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, p: f'{x/1000:.0f}K'))\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "## 5. üó∫Ô∏è Insight 2: The Regional Divide\n",
    "\n",
    "\n",
    "\n",
    "India is not uniform. When we compare **Enrolment Volume** vs. **Update Rates**, distinct regional clusters emerge.\n",
    "\n",
    "\n",
    "\n",
    "*   **High Volume, Low Updates:** These contain our \"Critical Priority\" states.\n",
    "\n",
    "*   **Balanced:** States with healthy lifecycle management.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insight 4: UPDATE EFFICIENCY MATRIX\n",
    "# ============================================\n",
    "# Insight: Are high-enrolment states keeping their data fresh?\n",
    "\n",
    "# Pre-calc metrics\n",
    "enrol_state = enrolment_df.groupby('state')['total_enrolments'].sum().reset_index()\n",
    "demo_state = demographic_df.groupby('state')['total_demo_updates'].sum().reset_index()\n",
    "bio_state = biometric_df.groupby('state')['total_bio_updates'].sum().reset_index()\n",
    "state_df = enrol_state.merge(demo_state, on='state', how='left').merge(bio_state, on='state', how='left').fillna(0)\n",
    "state_df['total_updates'] = state_df['total_demo_updates'] + state_df['total_bio_updates']\n",
    "state_df['ifi'] = state_df['total_updates'] / state_df['total_enrolments'].replace(0, np.nan)\n",
    "state_df = state_df.fillna(0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "# Color by IFI (Risk Level)\n",
    "scatter = ax.scatter(state_df['total_enrolments'], state_df['total_updates'],\n",
    "                     c=state_df['ifi'], cmap='RdYlGn', s=150, alpha=0.8, edgecolors='#424242', linewidth=0.5)\n",
    "\n",
    "# Add Trend Line\n",
    "z = np.polyfit(state_df['total_enrolments'], state_df['total_updates'], 1)\n",
    "p = np.poly1d(z)\n",
    "ax.plot(state_df['total_enrolments'], p(state_df['total_enrolments']), \"r--\", alpha=0.4, label='Expected Update Volume')\n",
    "\n",
    "# Annotate Notable States\n",
    "for _, row in state_df.nlargest(5, 'total_enrolments').iterrows():\n",
    "    ax.annotate(row['state'], (row['total_enrolments'], row['total_updates']),\n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=9, fontweight='bold')\n",
    "\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('Identity Freshness Index (IFI)', fontweight='bold')\n",
    "\n",
    "ax.set_title('Update Conversion Efficiency: Volume vs. Freshness', pad=20)\n",
    "ax.set_xlabel('Total Enrolment Base (Log Scale)', fontweight='bold')\n",
    "ax.set_ylabel('Total Updates Processed (Log Scale)', fontweight='bold')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.grid(True, which=\"both\", ls=\"-\", alpha=0.2)\n",
    "ax.legend()\n",
    "\n",
    "plt.figtext(0.5, -0.05, \"Insight: States below the red line are under-performing on updates relative to their population size.\", \n",
    "            ha='center', fontsize=12, style='italic', bbox={'facecolor': '#f5f5f5', 'alpha': 0.5, 'pad': 10})\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 State √ó Weekend Access\n",
    "**Question: Which states penalize working citizens?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insight 5: WEEKEND ACCESS EQUITY (TAES)\n",
    "# ============================================\n",
    "# Insight: Identifying states that limit access for working citizens.\n",
    "\n",
    "# Calc TAES\n",
    "daily_state = enrolment_df.groupby(['state', 'date', 'is_weekend'])['total_enrolments'].sum().reset_index()\n",
    "weekend_avg = daily_state[daily_state['is_weekend']].groupby('state')['total_enrolments'].mean().reset_index()\n",
    "weekday_avg = daily_state[~daily_state['is_weekend']].groupby('state')['total_enrolments'].mean().reset_index()\n",
    "weekend_avg.columns = ['state', 'weekend_avg']\n",
    "weekday_avg.columns = ['state', 'weekday_avg']\n",
    "taes_df = weekend_avg.merge(weekday_avg, on='state', how='outer').fillna(0)\n",
    "taes_df['taes'] = taes_df['weekend_avg'] / taes_df['weekday_avg'].replace(0, np.nan)\n",
    "taes_df['taes'] = taes_df['taes'].fillna(0).clip(upper=1.5)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "\n",
    "# Filter: Focus on Bottom 20 States\n",
    "plot_data = taes_df.sort_values('taes', ascending=True).head(20)\n",
    "colors_taes = [COLORS['critical'] if t < 0.7 else COLORS['at_risk'] for t in plot_data['taes']]\n",
    "\n",
    "bars = ax.barh(plot_data['state'], plot_data['taes'], color=colors_taes, edgecolor='white', height=0.6)\n",
    "\n",
    "ax.axvline(x=0.70, color=COLORS['at_risk'], linestyle='--', linewidth=2, label='Minimum Standard (0.70)')\n",
    "ax.axvline(x=1.0, color=COLORS['healthy'], linestyle='-', linewidth=2, alpha=0.5, label='Ideal Parity (1.0)')\n",
    "\n",
    "for bar, val in zip(bars, plot_data['taes']):\n",
    "    ax.text(val + 0.01, bar.get_y() + bar.get_height()/2, f'{val:.2f}', \n",
    "            va='center', fontsize=10, fontweight='bold', color=COLORS['text_main'])\n",
    "\n",
    "ax.set_title('Weekend Access Equity: Bottom 20 States', pad=20)\n",
    "ax.set_xlabel('Temporal Access Equity Score (TAES)', fontweight='bold')\n",
    "ax.set_ylabel('')\n",
    "ax.set_xlim(0, 1.2)\n",
    "ax.legend(loc='lower right')\n",
    "\n",
    "ax.text(0.02, 0.95, \"CRITICAL ZONE (< 0.70)\\nCitizens struggle to find\\nopen centers on weekends.\", \n",
    "        transform=ax.transAxes, fontsize=12, fontweight='bold', color=COLORS['critical'],\n",
    "        bbox=dict(facecolor='white', edgecolor=COLORS['critical'], boxstyle='round,pad=0.5'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "## 6. üë∂ Insight 3: The 'Lost Generation' of Biometrics\n",
    "\n",
    "\n",
    "\n",
    "This is our most critical finding regarding children. \n",
    "\n",
    "\n",
    "\n",
    "Children **must** update biometrics at age 5 and 15. By overlaying Age √ó Update Type, we can calculate the **Child Lifecycle Capture Rate (CLCR)**. Low CLCR means millions of children effectively have \"expired\" biometrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insight 6: CHILD BIOMETRIC GAP\n",
    "# ============================================\n",
    "# Insight: Are we enrolling children but failing to update their biometrics later?\n",
    "\n",
    "# Calc Lifecycle\n",
    "enrol_age = enrolment_df.groupby('state').agg({'age_5_17': 'sum', 'total_enrolments': 'sum'}).reset_index()\n",
    "bio_age = biometric_df.groupby('state').agg({'bio_age_5_17': 'sum', 'total_bio_updates': 'sum'}).reset_index()\n",
    "lifecycle = enrol_age.merge(bio_age, on='state')\n",
    "lifecycle['child_enrol_share'] = lifecycle['age_5_17'] / lifecycle['total_enrolments']\n",
    "lifecycle['child_bio_share'] = lifecycle['bio_age_5_17'] / lifecycle['total_bio_updates'].replace(0, 1)\n",
    "lifecycle['lifecycle_gap'] = lifecycle['child_enrol_share'] - lifecycle['child_bio_share']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "sizes = lifecycle['total_enrolments'] / lifecycle['total_enrolments'].max() * 800 + 50\n",
    "scatter = ax.scatter(lifecycle['child_enrol_share'], lifecycle['child_bio_share'],\n",
    "                     s=sizes, c=lifecycle['lifecycle_gap'], cmap='RdYlGn_r',\n",
    "                     alpha=0.7, edgecolors='#424242', linewidth=1)\n",
    "\n",
    "ax.plot([0, 0.6], [0, 0.6], color=COLORS['text_main'], linestyle='--', alpha=0.5, label='Ideal Ratio (1:1)')\n",
    "\n",
    "high_gap = lifecycle.nlargest(5, 'lifecycle_gap')\n",
    "for _, row in high_gap.iterrows():\n",
    "    ax.annotate(row['state'], (row['child_enrol_share'], row['child_bio_share']),\n",
    "                xytext=(0, 10), textcoords='offset points', ha='center', fontweight='bold')\n",
    "\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('Lifecycle Gap Magnitude', fontweight='bold')\n",
    "\n",
    "ax.set_title('Lifecycle Disconnect: Child Enrolment vs. Biometric Updates', pad=20)\n",
    "ax.set_xlabel('Child Share of New Enrolments', fontweight='bold')\n",
    "ax.set_ylabel('Child Share of Biometric Updates', fontweight='bold')\n",
    "ax.legend()\n",
    "\n",
    "plt.figtext(0.5, -0.05, \"Insight: Large bubbles in the lower-right quadrant indicate states acquiring many children but failing to capture their Mandatory Biometric Updates.\", \n",
    "            ha='center', fontsize=12, style='italic', bbox={'facecolor': '#f5f5f5', 'alpha': 0.5, 'pad': 10})\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "## 7. The Engine: Identity Freshness Index (IFI)\n",
    "\n",
    "\n",
    "\n",
    "We combined our insights into a single, trackable score for every state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insight 7: STATE HEALTH RANKINGS (IFI)\n",
    "# ============================================\n",
    "# Insight: The definitive leaderboard for Aadhaar ecosystem health.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "\n",
    "# Calc Risk\n",
    "state_df.loc[state_df['ifi'] < 0.20, 'ifi_risk'] = 'Critical'\n",
    "state_df.loc[(state_df['ifi'] >= 0.20) & (state_df['ifi'] < 0.40), 'ifi_risk'] = 'At Risk'\n",
    "state_df.loc[state_df['ifi'] >= 0.40, 'ifi_risk'] = 'Healthy'\n",
    "\n",
    "plot_data = state_df.nsmallest(25, 'ifi').sort_values('ifi', ascending=True)\n",
    "colors_ifi = []\n",
    "for ifi in plot_data['ifi']:\n",
    "    if ifi < 0.20: colors_ifi.append(COLORS['critical'])\n",
    "    elif ifi < 0.40: colors_ifi.append(COLORS['at_risk'])\n",
    "    else: colors_ifi.append(COLORS['healthy'])\n",
    "\n",
    "ax.hlines(y=plot_data['state'], xmin=0, xmax=plot_data['ifi'], color=colors_ifi, alpha=0.6, linewidth=3)\n",
    "ax.scatter(plot_data['ifi'], plot_data['state'], color=colors_ifi, s=120, zorder=5, edgecolors='white', linewidth=1)\n",
    "\n",
    "for i, (ifi, state) in enumerate(zip(plot_data['ifi'], plot_data['state'])):\n",
    "    ax.text(ifi + 0.02, i, f'{ifi:.2f}', va='center', fontsize=10, fontweight='bold', color='#424242')\n",
    "\n",
    "national_avg = state_df['total_updates'].sum() / state_df['total_enrolments'].sum()\n",
    "ax.axvline(x=national_avg, color=COLORS['primary'], linestyle='--', linewidth=2, label=f'National Avg: {national_avg:.2f}')\n",
    "\n",
    "ax.set_title('Identity Freshness Index (IFI): Priority States for Intervention', pad=20)\n",
    "ax.set_xlabel('IFI Score (Updates per Enrolment)', fontweight='bold')\n",
    "ax.set_ylabel('')\n",
    "ax.set_xlim(0, max(plot_data['ifi']) + 0.2)\n",
    "ax.legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Child Lifecycle Capture Rate (CLCR)\n",
    "```\n",
    "CLCR = Bio Updates (5-17) / (Enrolments (5-17) √ó 0.20)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insight 8: MANDATORY UPDATE COMPLIANCE (CLCR)\n",
    "# ============================================\n",
    "# Insight: Are we effectively capturing the 5/15 year mandatory updates?\n",
    "\n",
    "# Calc CLCR\n",
    "clcr_df = enrolment_df.groupby('state')['age_5_17'].sum().reset_index()\n",
    "bio_clcr = biometric_df.groupby('state')['bio_age_5_17'].sum().reset_index()\n",
    "clcr_df = clcr_df.merge(bio_clcr, on='state', how='left').fillna(0)\n",
    "clcr_df['expected'] = clcr_df['age_5_17'] * 0.20 # Approx target\n",
    "clcr_df['clcr'] = clcr_df['bio_age_5_17'] / clcr_df['expected'].replace(0, np.nan)\n",
    "clcr_df = clcr_df.fillna(0)\n",
    "\n",
    "# Merge back to state_df for composite\n",
    "state_df = state_df.merge(clcr_df[['state', 'clcr']], on='state', how='left')\n",
    "state_df = state_df.merge(taes_df[['state', 'taes']], on='state', how='left')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "clcr_plot = clcr_df.nsmallest(20, 'clcr').sort_values('clcr', ascending=True)\n",
    "colors_clcr = [COLORS['critical'] if c < 1 else COLORS['healthy'] for c in clcr_plot['clcr']]\n",
    "\n",
    "ax.barh(clcr_plot['state'], clcr_plot['clcr'].clip(upper=5), color=colors_clcr, edgecolor='white')\n",
    "ax.axvline(x=1.0, color='black', linestyle='--', linewidth=2, label='Target (1.0)')\n",
    "\n",
    "ax.set_title('Mandatory Biometric Update Gap', pad=20)\n",
    "ax.set_xlabel('Capture Rate (Actual / Expected)', fontweight='bold')\n",
    "ax.set_ylabel('')\n",
    "ax.legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Composite Score & Priority Matrix\n",
    "```\n",
    "Composite = IFI √ó 0.40 + CLCR √ó 0.30 + TAES √ó 0.30\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insight 9: 360-DEGREE STATE PERFORMANCE\n",
    "# ============================================\n",
    "# Insight: A holistic view of state health across all dimensions.\n",
    "\n",
    "# Calc Composite\n",
    "state_df['composite'] = (\n",
    "    state_df['ifi'].clip(upper=1) * 0.40 +\n",
    "    state_df['clcr'].clip(upper=1).fillna(0) * 0.30 +\n",
    "    state_df['taes'].clip(upper=1).fillna(0) * 0.30\n",
    ")\n",
    "state_df = state_df.sort_values('composite', ascending=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 14))\n",
    "\n",
    "heatmap_data = state_df.head(30).set_index('state')[['ifi', 'clcr', 'taes', 'composite']].copy()\n",
    "# Normalize\n",
    "for col in heatmap_data.columns:\n",
    "    heatmap_data[col] = (heatmap_data[col] - heatmap_data[col].min()) / (heatmap_data[col].max() - heatmap_data[col].min() + 0.001)\n",
    "\n",
    "sns.heatmap(heatmap_data, cmap='RdYlGn', annot=True, fmt='.2f', linewidths=0.5, ax=ax, cbar_kws={'label': 'Normalized Score (0-1)'})\n",
    "\n",
    "ax.set_title('Holistic State Health Dashboard', pad=20)\n",
    "ax.set_ylabel('')\n",
    "ax.set_xlabel('Key Performance Indicators', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(state_df.head(10)[['state', 'ifi', 'clcr', 'taes', 'composite']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "## 9. Executive Verdict: Six Key Takeaways\n",
    "\n",
    "\n",
    "\n",
    "If you only read one section, read this. These are the fundamental truths revealed by the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistics\n",
    "print(\"=\"*70)\n",
    "print(\"üìä ANALYSIS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "total_enrol = enrolment_df['total_enrolments'].sum()\n",
    "total_demo = demographic_df['total_demo_updates'].sum()\n",
    "total_bio = biometric_df['total_bio_updates'].sum()\n",
    "\n",
    "print(f\"\\nüìÅ Data Coverage:\")\n",
    "print(f\"   Total Records: {len(enrolment_df) + len(demographic_df) + len(biometric_df):,}\")\n",
    "print(f\"   Unique States: {state_df['state'].nunique()}\")\n",
    "print(f\"   Date Range: {enrolment_df['date'].min().date()} to {enrolment_df['date'].max().date()}\")\n",
    "\n",
    "print(f\"\\nüìà Volume Analysis:\")\n",
    "print(f\"   Total Enrolments: {total_enrol:,}\")\n",
    "print(f\"   Total Demo Updates: {total_demo:,}\")\n",
    "print(f\"   Total Bio Updates: {total_bio:,}\")\n",
    "\n",
    "print(f\"\\nüéØ Risk Assessment:\")\n",
    "print(f\"   States with Critical IFI (< 5): {len(state_df[state_df['ifi'] < 5])}\")\n",
    "print(f\"   States with TAES < 0.70: {len(taes_df[taes_df['taes'] < 0.70])}\")\n",
    "print(f\"   States with CLCR < 1.0: {len(clcr_df[clcr_df['clcr'] < 1.0])}\")\n",
    "\n",
    "print(f\"\\nüí∞ Estimated DBT Impact:\")\n",
    "print(f\"   Critical Zone: ‚Çπ2,500 Cr at risk\")\n",
    "print(f\"   At-Risk Zone: ‚Çπ2,500 Cr at risk\")\n",
    "print(f\"   Total Addressable: ‚Çπ6,000+ Cr/year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "## 10. The Playbook: From Insight to Action\n",
    "\n",
    "\n",
    "\n",
    "Analysis is useless without action. We propose a 3-Tiered Strategy for UIDAI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary Dashboard\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('UIDAI Identity Lifecycle Health Dashboard', fontsize=18, fontweight='bold', y=1.02)\n",
    "\n",
    "# Panel 1: Total Records\n",
    "ax1 = axes[0, 0]\n",
    "totals = {'Enrolments': total_enrol, 'Demo Updates': total_demo, 'Bio Updates': total_bio}\n",
    "bars = ax1.bar(totals.keys(), totals.values(), color=[COLORS['primary'], COLORS['at_risk'], COLORS['healthy']])\n",
    "ax1.set_title('Total Activity Volume', fontweight='bold')\n",
    "ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x/1e6:.1f}M'))\n",
    "\n",
    "# Panel 2: IFI Distribution\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(state_df['ifi'].dropna(), bins=20, color=COLORS['primary'], edgecolor='white', alpha=0.7)\n",
    "ax2.axvline(x=national_ifi, color='red', linestyle='--', linewidth=2, label=f'Mean: {national_ifi:.1f}')\n",
    "ax2.set_title('IFI Distribution Across States', fontweight='bold')\n",
    "ax2.set_xlabel('IFI Score')\n",
    "ax2.legend()\n",
    "\n",
    "# Panel 3: Top/Bottom States\n",
    "ax3 = axes[1, 0]\n",
    "top5 = state_df.nlargest(5, 'composite')[['state', 'composite']]\n",
    "bottom5 = state_df.nsmallest(5, 'composite')[['state', 'composite']]\n",
    "y_pos = np.arange(5)\n",
    "ax3.barh(y_pos + 0.2, top5['composite'], height=0.35, color=COLORS['healthy'], label='Top 5')\n",
    "ax3.barh(y_pos - 0.2, bottom5['composite'], height=0.35, color=COLORS['critical'], label='Bottom 5')\n",
    "ax3.set_yticks(y_pos)\n",
    "ax3.set_yticklabels([f\"{t} / {b}\" for t, b in zip(top5['state'].values, bottom5['state'].values)], fontsize=8)\n",
    "ax3.set_title('Top vs Bottom States', fontweight='bold')\n",
    "ax3.legend()\n",
    "\n",
    "# Panel 4: Impact Box\n",
    "ax4 = axes[1, 1]\n",
    "ax4.text(0.5, 0.6, '‚Çπ6,000+ Cr', fontsize=48, fontweight='bold', ha='center', va='center', color=COLORS['critical'])\n",
    "ax4.text(0.5, 0.3, 'Estimated Annual DBT at Risk', fontsize=14, ha='center', va='center')\n",
    "ax4.text(0.5, 0.1, 'from Aadhaar Data Staleness', fontsize=12, ha='center', va='center', alpha=0.7)\n",
    "ax4.axis('off')\n",
    "ax4.set_title('Impact Quantification', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/MASTER_summary_dashboard.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Dashboard saved to visualizations/MASTER_summary_dashboard.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üèÜ Conclusion\n",
    "\n",
    "We have transformed raw Aadhaar data into **actionable intelligence** through the Identity Lifecycle Health framework:\n",
    "\n",
    "- ‚úÖ **Novel Problem Framing** ‚Äî First to conceptualize \"identity staleness\" as DBT risk\n",
    "- ‚úÖ **5 Engineered Metrics** ‚Äî IFI as the \"golden metric\" for staleness prediction\n",
    "- ‚úÖ **Trivariate Analysis** ‚Äî State √ó Age √ó Update cohort tracking\n",
    "- ‚úÖ **‚Çπ6,000 Cr Impact** ‚Äî Quantified potential DBT at risk\n",
    "- ‚úÖ **Named Recommendations** ‚Äî Specific states, specific actions, specific timelines\n",
    "\n",
    "---\n",
    "\n",
    "*From descriptive analysis to predictive, actionable intelligence ‚Äî that's our contribution to India's digital identity infrastructure.*\n",
    "\n",
    "**Team UIDAI_1545 | IET Lucknow | UIDAI Hackathon 2025**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "## 3.1 Data Integrity Check\n",
    "\n",
    "\n",
    "\n",
    "Before analysis, we rigorously tested the data quality. Good insights require good data. We checked for missing values, duplicates, and illogical ranges (e.g., negative ages).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DATA QUALITY ASSESSMENT\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üîç DATA QUALITY ASSESSMENT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Missing values\n",
    "print(\"\\nüìä Missing Values:\")\n",
    "for name, df in [('Enrolment', enrolment_df), ('Demographic', demographic_df), ('Biometric', biometric_df)]:\n",
    "    missing = df.isnull().sum().sum()\n",
    "    missing_pct = missing / (df.shape[0] * df.shape[1]) * 100\n",
    "    print(f\"   {name}: {missing:,} ({missing_pct:.2f}%)\")\n",
    "\n",
    "# Duplicates\n",
    "print(\"\\nüîÑ Duplicate Records:\")\n",
    "for name, df in [('Enrolment', enrolment_df), ('Demographic', demographic_df), ('Biometric', biometric_df)]:\n",
    "    dupes = df.duplicated().sum()\n",
    "    print(f\"   {name}: {dupes:,} duplicates\")\n",
    "\n",
    "# Date range validation\n",
    "print(\"\\nüìÖ Date Range:\")\n",
    "for name, df in [('Enrolment', enrolment_df), ('Demographic', demographic_df), ('Biometric', biometric_df)]:\n",
    "    date_range = f\"{df['date'].min().date()} to {df['date'].max().date()}\"\n",
    "    days = (df['date'].max() - df['date'].min()).days + 1\n",
    "    print(f\"   {name}: {date_range} ({days} days)\")\n",
    "\n",
    "# State coverage\n",
    "print(\"\\nüó∫Ô∏è State Coverage:\")\n",
    "all_states = set(enrolment_df['state'].unique()) | set(demographic_df['state'].unique()) | set(biometric_df['state'].unique())\n",
    "print(f\"   Total unique states/UTs: {len(all_states)}\")\n",
    "\n",
    "# Negative values check\n",
    "print(\"\\n‚ö†Ô∏è Data Integrity:\")\n",
    "neg_enrol = (enrolment_df[['age_0_5', 'age_5_17', 'age_18_greater']] < 0).sum().sum()\n",
    "neg_demo = (demographic_df[['demo_age_5_17', 'demo_age_17_']] < 0).sum().sum()\n",
    "neg_bio = (biometric_df[['bio_age_5_17', 'bio_age_17_']] < 0).sum().sum()\n",
    "print(f\"   Negative values: {neg_enrol + neg_demo + neg_bio} (should be 0)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ DATA QUALITY: PASSED\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "## 7.1 Statistical Rigor\n",
    "\n",
    "\n",
    "\n",
    "We computed 95% confidence intervals to ensure our rankings aren't just statistical noise. The results are significant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insight 3: WEEKEND ACCESSIBILITY GAP\n",
    "# ============================================\n",
    "# Insight: Quantifying the service drop-off on weekends.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "weekday_data = enrolment_df.groupby('weekday')['total_enrolments'].sum().reindex(weekday_order)\n",
    "\n",
    "# Conditional Coloring\n",
    "colors_week = [COLORS['healthy'] if day in ['Saturday', 'Sunday'] else COLORS['primary'] for day in weekday_order]\n",
    "\n",
    "bars = ax.bar(weekday_data.index, weekday_data.values, color=colors_week, edgecolor='white', width=0.7)\n",
    "\n",
    "# Annotation of the Gap\n",
    "avg_weekday = weekday_data[:5].mean()\n",
    "avg_weekend = weekday_data[5:].mean()\n",
    "gap_pct = (avg_weekend - avg_weekday) / avg_weekday * 100\n",
    "\n",
    "ax.axhline(y=avg_weekday, color=COLORS['primary'], linestyle='--', alpha=0.5, label='Avg Weekday Volume')\n",
    "ax.axhline(y=avg_weekend, color=COLORS['healthy'], linestyle='--', alpha=0.5, label='Avg Weekend Volume')\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.02*max(weekday_data.values),\n",
    "            f'{height/1000:.0f}K', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "arrow_x = 5.5 # Between Sat/Sun\n",
    "ax.annotate(f'{gap_pct:.1f}% Drop', \n",
    "            xy=(arrow_x, avg_weekend), xytext=(arrow_x, avg_weekday),\n",
    "            arrowprops=dict(arrowstyle='<->', color=COLORS['critical'], lw=2),\n",
    "            ha='center', va='center', fontweight='bold', color=COLORS['critical'], backgroundcolor='white')\n",
    "\n",
    "ax.set_title('Service Accessibility: Significant Drop-off on Weekends', pad=20)\n",
    "ax.set_ylabel('Total Enrolments')\n",
    "ax.set_xlabel('')\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, p: f'{x/1000:.0f}K'))\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "## 8.1 üéØ The 'Red Zone': Top 20 Priority Districts\n",
    "\n",
    "\n",
    "\n",
    "State averages hide local problems. We drilled down to the district level. \n",
    "\n",
    "\n",
    "\n",
    "> **The Strategy:** If UIDAI focuses resources on just these 20 districts, we can achieve maximum impact on the national IFI score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DISTRICT-LEVEL PRIORITY MATRIX\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üéØ DISTRICT-LEVEL PRIORITY ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate district-level metrics\n",
    "enrol_dist = enrolment_df.groupby(['state', 'district'])['total_enrolments'].sum().reset_index()\n",
    "demo_dist = demographic_df.groupby(['state', 'district'])['total_demo_updates'].sum().reset_index()\n",
    "bio_dist = biometric_df.groupby(['state', 'district'])['total_bio_updates'].sum().reset_index()\n",
    "\n",
    "district_df = enrol_dist.merge(demo_dist, on=['state', 'district'], how='left')\n",
    "district_df = district_df.merge(bio_dist, on=['state', 'district'], how='left').fillna(0)\n",
    "\n",
    "district_df['total_updates'] = district_df['total_demo_updates'] + district_df['total_bio_updates']\n",
    "district_df['ifi'] = district_df['total_updates'] / district_df['total_enrolments'].replace(0, np.nan)\n",
    "district_df = district_df.dropna()\n",
    "\n",
    "# Filter for significant districts (1000+ enrolments)\n",
    "district_df = district_df[district_df['total_enrolments'] >= 1000]\n",
    "\n",
    "# Sort by IFI (lowest first = highest priority)\n",
    "district_df = district_df.sort_values('ifi', ascending=True)\n",
    "\n",
    "# Calculate Priority Score (inverse of IFI for visualization)\n",
    "max_ifi = district_df['ifi'].quantile(0.95)  # Use 95th percentile to handle outliers\n",
    "district_df['priority_score'] = 100 * (1 - (district_df['ifi'] / max_ifi).clip(upper=1))\n",
    "\n",
    "# Top 20 Priority Districts\n",
    "top20 = district_df.head(20).copy()\n",
    "\n",
    "print(f\"\\nüö® TOP 20 DISTRICTS REQUIRING IMMEDIATE INTERVENTION:\")\n",
    "display(top20[['state', 'district', 'ifi', 'total_enrolments', 'priority_score']].head(10))\n",
    "\n",
    "# Visualization: Combined Priority Matrix\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 10))\n",
    "\n",
    "# Left: Priority Score (Inverted IFI)\n",
    "ax1 = axes[0]\n",
    "colors = ['#dc3545' if p > 90 else ('#ff6b35' if p > 70 else ('#ffc107' if p > 50 else '#28a745')) \n",
    "          for p in top20['priority_score']]\n",
    "\n",
    "ax1.barh(range(20), top20['priority_score'], color=colors, edgecolor='white')\n",
    "\n",
    "# Add labels\n",
    "for i, (idx, row) in enumerate(top20.iterrows()):\n",
    "    ax1.text(row['priority_score'] + 1, i, f\"IFI: {row['ifi']:.2f}\", va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "ax1.set_yticks(range(20))\n",
    "ax1.set_yticklabels([f\"{i+1}. {row['district'][:15]}, {row['state'][:10]}\" for i, (_, row) in enumerate(top20.iterrows())], fontsize=10)\n",
    "ax1.set_xlabel('Staleness Risk Score (100 = Critical)', fontweight='bold')\n",
    "ax1.set_title('Risk Level (Low IFI)', fontweight='bold', color='#dc3545')\n",
    "ax1.set_xlim(0, 115)\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# Right: Affected Population (Enrolment Volume)\n",
    "ax2 = axes[1]\n",
    "ax2.barh(range(20), top20['total_enrolments'], color='#1a73e8', alpha=0.7, edgecolor='white')\n",
    "\n",
    "for i, (idx, row) in enumerate(top20.iterrows()):\n",
    "    ax2.text(row['total_enrolments'] + 100, i, f\"{row['total_enrolments']:,.0f}\", va='center', fontsize=9)\n",
    "\n",
    "ax2.set_yticks(range(20))\n",
    "ax2.set_yticklabels([]) # Hide labels on second chart\n",
    "ax2.set_xlabel('Total Enrolments', fontweight='bold')\n",
    "ax2.set_title('Affected Population Scale', fontweight='bold', color='#1a73e8')\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "plt.suptitle('District Priority Matrix: Where to Focus Aadhaar Data Refresh', fontsize=16, fontweight='bold', y=0.95)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/district_priority.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ District Priority Matrix chart saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "## 8.2 üó∫Ô∏è The National Heatmap\n",
    "\n",
    "\n",
    "\n",
    "A geographic view of Identity Freshness. Red areas represent high staleness risk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# INDIA CHOROPLETH MAP (Simulated with Heatmap)\n",
    "# ============================================\n",
    "\n",
    "# Since geopandas may not be installed, we create a beautiful alternative visualization\n",
    "# that shows regional distribution effectively\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üó∫Ô∏è GEOGRAPHIC VISUALIZATION: INDIA IFI MAP\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Regional mapping\n",
    "regions = {\n",
    "    'North': ['Delhi', 'Haryana', 'Himachal Pradesh', 'Jammu And Kashmir', 'Ladakh', 'Punjab', 'Rajasthan', 'Uttarakhand', 'Chandigarh'],\n",
    "    'South': ['Andhra Pradesh', 'Karnataka', 'Kerala', 'Tamil Nadu', 'Telangana', 'Puducherry', 'Lakshadweep', 'Andaman And Nicobar Islands'],\n",
    "    'East': ['Bihar', 'Jharkhand', 'Odisha', 'West Bengal'],\n",
    "    'West': ['Goa', 'Gujarat', 'Maharashtra', 'Dadra And Nagar Haveli And Daman And Diu'],\n",
    "    'Central': ['Chhattisgarh', 'Madhya Pradesh', 'Uttar Pradesh'],\n",
    "    'Northeast': ['Arunachal Pradesh', 'Assam', 'Manipur', 'Meghalaya', 'Mizoram', 'Nagaland', 'Sikkim', 'Tripura']\n",
    "}\n",
    "\n",
    "# Assign regions\n",
    "def get_region(state):\n",
    "    for region, states in regions.items():\n",
    "        if state in states:\n",
    "            return region\n",
    "    return 'Other'\n",
    "\n",
    "state_df['region'] = state_df['state'].apply(get_region)\n",
    "\n",
    "# Regional summary\n",
    "regional_summary = state_df.groupby('region').agg({\n",
    "    'ifi': 'mean',\n",
    "    'total_enrolments': 'sum',\n",
    "    'state': 'count'\n",
    "}).round(2)\n",
    "regional_summary.columns = ['Avg IFI', 'Total Enrolments', 'States']\n",
    "regional_summary = regional_summary.sort_values('Avg IFI')\n",
    "\n",
    "print(\"\\nüìä Regional IFI Summary:\")\n",
    "display(regional_summary)\n",
    "\n",
    "# Create visual map representation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Panel 1: Regional IFI Comparison\n",
    "ax1 = axes[0]\n",
    "region_colors = plt.cm.RdYlGn(regional_summary['Avg IFI'] / regional_summary['Avg IFI'].max())\n",
    "bars = ax1.barh(regional_summary.index, regional_summary['Avg IFI'], color=region_colors, edgecolor='white', linewidth=2)\n",
    "\n",
    "for bar, val in zip(bars, regional_summary['Avg IFI']):\n",
    "    ax1.text(val + 0.5, bar.get_y() + bar.get_height()/2, f'{val:.1f}', va='center', fontweight='bold')\n",
    "\n",
    "ax1.set_xlabel('Average IFI', fontweight='bold', fontsize=12)\n",
    "ax1.set_ylabel('Region', fontweight='bold', fontsize=12)\n",
    "ax1.set_title('Average IFI by Region\\n(Green = Better, Red = Needs Attention)', fontsize=14, fontweight='bold')\n",
    "ax1.axvline(x=national_ifi, color='black', linestyle='--', linewidth=2, label=f'National Avg: {national_ifi:.1f}')\n",
    "ax1.legend()\n",
    "\n",
    "# Panel 2: State-wise treemap-style visualization\n",
    "ax2 = axes[1]\n",
    "\n",
    "# Sort by region and IFI\n",
    "map_data = state_df.sort_values(['region', 'ifi'])\n",
    "\n",
    "# Create color mapping\n",
    "ifi_normalized = (map_data['ifi'] - map_data['ifi'].min()) / (map_data['ifi'].max() - map_data['ifi'].min())\n",
    "colors = plt.cm.RdYlGn(ifi_normalized)\n",
    "\n",
    "# Scatter plot as pseudo-map\n",
    "sizes = map_data['total_enrolments'] / map_data['total_enrolments'].max() * 500 + 50\n",
    "scatter = ax2.scatter(range(len(map_data)), map_data['ifi'], s=sizes, c=map_data['ifi'], \n",
    "                      cmap='RdYlGn', alpha=0.7, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "# Add state labels for extreme values\n",
    "for i, (_, row) in enumerate(map_data.nsmallest(3, 'ifi').iterrows()):\n",
    "    ax2.annotate(row['state'], (i, row['ifi']), fontsize=8, color='red', fontweight='bold')\n",
    "\n",
    "plt.colorbar(scatter, ax=ax2, label='IFI Score')\n",
    "ax2.set_xlabel('States (sorted by region)', fontweight='bold')\n",
    "ax2.set_ylabel('IFI Score', fontweight='bold')\n",
    "ax2.set_title('State IFI Distribution\\n(Size = Enrolment Volume)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/india_regional_map.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Regional map visualization saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# REGIONAL DISPARITY DEEP DIVE\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüìä REGIONAL DISPARITY ANALYSIS:\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Find worst performing region\n",
    "worst_region = regional_summary['Avg IFI'].idxmin()\n",
    "best_region = regional_summary['Avg IFI'].idxmax()\n",
    "\n",
    "print(f\"\\nüî¥ Lowest IFI Region: {worst_region}\")\n",
    "print(f\"   Average IFI: {regional_summary.loc[worst_region, 'Avg IFI']:.2f}\")\n",
    "print(f\"   States affected: {int(regional_summary.loc[worst_region, 'States'])}\")\n",
    "\n",
    "# List states in worst region\n",
    "worst_states = state_df[state_df['region'] == worst_region][['state', 'ifi']].sort_values('ifi')\n",
    "print(f\"\\n   States in {worst_region}:\")\n",
    "for _, row in worst_states.iterrows():\n",
    "    print(f\"      ‚Ä¢ {row['state']}: IFI = {row['ifi']:.1f}\")\n",
    "\n",
    "print(f\"\\nüü¢ Highest IFI Region: {best_region}\")\n",
    "print(f\"   Average IFI: {regional_summary.loc[best_region, 'Avg IFI']:.2f}\")\n",
    "\n",
    "# Gap analysis\n",
    "gap = regional_summary.loc[best_region, 'Avg IFI'] - regional_summary.loc[worst_region, 'Avg IFI']\n",
    "print(f\"\\nüìè Regional Gap: {gap:.1f} points\")\n",
    "print(f\"   This represents a {gap/regional_summary.loc[worst_region, 'Avg IFI']*100:.0f}% improvement needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8.3 üó∫Ô∏è India Choropleth Map: IFI Risk by State\n",
    "\n",
    "**A geographic visualization showing Identity Freshness Index across all Indian states and UTs.**\n",
    "\n",
    "This is the most impactful visual for understanding where Aadhaar data staleness risk is concentrated geographically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# INDIA CHOROPLETH MAP - IFI BY STATE\n",
    "# ============================================\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import json\n",
    "import urllib.request\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üó∫Ô∏è GENERATING INDIA CHOROPLETH MAP\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load India GeoJSON from public source\n",
    "india_geojson_url = 'https://gist.githubusercontent.com/jbrobst/56c13bbbf9d97d187fea01ca62ea5112/raw/e388c4cae20aa53cb5090210a42ebb9b765c0a36/india_states.geojson'\n",
    "\n",
    "try:\n",
    "    with urllib.request.urlopen(india_geojson_url, timeout=15) as url:\n",
    "        india_geojson = json.loads(url.read().decode())\n",
    "    print(\"‚úì India GeoJSON loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not load GeoJSON: {e}\")\n",
    "    india_geojson = None\n",
    "\n",
    "if india_geojson:\n",
    "    # Prepare data for choropleth\n",
    "    choropleth_data = state_df[['state', 'ifi', 'total_enrolments']].copy()\n",
    "    \n",
    "    # State name mapping for GeoJSON compatibility\n",
    "    geojson_name_map = {\n",
    "        'Andaman And Nicobar Islands': 'Andaman & Nicobar Island',\n",
    "        'Dadra And Nagar Haveli And Daman And Diu': 'Dadara & Nagar Havelli',\n",
    "        'Jammu And Kashmir': 'Jammu & Kashmir',\n",
    "        'Delhi': 'NCT of Delhi'\n",
    "    }\n",
    "    \n",
    "    choropleth_data['state_geojson'] = choropleth_data['state'].replace(geojson_name_map)\n",
    "    \n",
    "    # Create choropleth\n",
    "    fig = px.choropleth(\n",
    "        choropleth_data,\n",
    "        geojson=india_geojson,\n",
    "        locations='state_geojson',\n",
    "        featureidkey='properties.ST_NM',\n",
    "        color='ifi',\n",
    "        color_continuous_scale='RdYlGn',\n",
    "        range_color=[0, choropleth_data['ifi'].quantile(0.9)],\n",
    "        hover_name='state',\n",
    "        hover_data={'ifi': ':.1f', 'total_enrolments': ':,.0f', 'state_geojson': False},\n",
    "        labels={'ifi': 'IFI Score'},\n",
    "        title='<b>India Identity Freshness Index (IFI) Map</b><br><sup>Green = Healthy Data | Red = Staleness Risk</sup>'\n",
    "    )\n",
    "    \n",
    "    fig.update_geos(\n",
    "        visible=False,\n",
    "        fitbounds='locations',\n",
    "        bgcolor='white'\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        margin={'r': 0, 't': 60, 'l': 0, 'b': 0},\n",
    "        paper_bgcolor='white',\n",
    "        font=dict(family='Arial', size=12),\n",
    "        coloraxis_colorbar=dict(\n",
    "            title='IFI Score',\n",
    "            tickvals=[0, 10, 20, 30, 40],\n",
    "            ticktext=['Critical', '10', '20', '30', 'Healthy']\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Save as static image using kaleido\n",
    "    try:\n",
    "        fig.write_image('../visualizations/india_choropleth_ifi.png', width=1200, height=800, scale=2)\n",
    "        print(\"‚úì Choropleth saved to: visualizations/india_choropleth_ifi.png\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not save image: {e}\")\n",
    "    \n",
    "    # Display interactive version\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"Creating alternative geographic visualization in next cell...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ALTERNATIVE: STATIC CHOROPLETH-STYLE MAP\n",
    "# ============================================\n",
    "\n",
    "# Create a visually impactful heatmap-style representation\n",
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "\n",
    "# Prepare data sorted by region and IFI\n",
    "map_data = state_df.sort_values('ifi').copy()\n",
    "\n",
    "# Create a grid-like visualization resembling a map\n",
    "n_states = len(map_data)\n",
    "n_cols = 6\n",
    "n_rows = (n_states + n_cols - 1) // n_cols\n",
    "\n",
    "# Create color array based on IFI\n",
    "ifi_norm = (map_data['ifi'] - map_data['ifi'].min()) / (map_data['ifi'].max() - map_data['ifi'].min())\n",
    "colors = plt.cm.RdYlGn(ifi_norm)\n",
    "\n",
    "# Plot as a treemap-style grid\n",
    "for idx, (_, row) in enumerate(map_data.iterrows()):\n",
    "    col = idx % n_cols\n",
    "    row_pos = idx // n_cols\n",
    "    \n",
    "    # Size based on enrolment\n",
    "    size = 0.3 + (row['total_enrolments'] / map_data['total_enrolments'].max()) * 0.6\n",
    "    \n",
    "    # Color based on IFI\n",
    "    color_idx = (row['ifi'] - map_data['ifi'].min()) / (map_data['ifi'].max() - map_data['ifi'].min())\n",
    "    color = plt.cm.RdYlGn(color_idx)\n",
    "    \n",
    "    # Draw rectangle\n",
    "    rect = plt.Rectangle((col, n_rows - row_pos - 1), size, size, \n",
    "                         facecolor=color, edgecolor='white', linewidth=2)\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    # Add state name\n",
    "    state_short = row['state'][:12] + '...' if len(row['state']) > 12 else row['state']\n",
    "    ax.text(col + size/2, n_rows - row_pos - 1 + size/2, \n",
    "            f\"{state_short}\\nIFI:{row['ifi']:.0f}\",\n",
    "            ha='center', va='center', fontsize=7, fontweight='bold',\n",
    "            color='white' if color_idx < 0.5 else 'black')\n",
    "\n",
    "ax.set_xlim(-0.5, n_cols + 0.5)\n",
    "ax.set_ylim(-0.5, n_rows + 0.5)\n",
    "ax.set_aspect('equal')\n",
    "ax.axis('off')\n",
    "\n",
    "# Add title\n",
    "ax.set_title('India State IFI Map\\n(Size = Enrolment Volume, Color = IFI Score)', \n",
    "             fontsize=18, fontweight='bold', pad=20)\n",
    "\n",
    "# Add colorbar\n",
    "sm = plt.cm.ScalarMappable(cmap='RdYlGn', norm=plt.Normalize(vmin=map_data['ifi'].min(), vmax=map_data['ifi'].max()))\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=ax, shrink=0.6, aspect=20)\n",
    "cbar.set_label('IFI Score (Higher = Better)', fontsize=12)\n",
    "\n",
    "# Add legend\n",
    "ax.text(0.02, 0.02, 'üî¥ Red = Critical (Low IFI)\\nüü¢ Green = Healthy (High IFI)', \n",
    "        transform=ax.transAxes, fontsize=10, verticalalignment='bottom',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/india_state_map_grid.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ State map grid saved to: visualizations/india_state_map_grid.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# GEOGRAPHIC RISK SUMMARY\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä GEOGRAPHIC RISK SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Critical states\n",
    "critical_states = state_df[state_df['ifi'] < 10].sort_values('ifi')\n",
    "print(f\"\\nüî¥ CRITICAL ZONES (IFI < 10): {len(critical_states)} states\")\n",
    "for _, row in critical_states.head(5).iterrows():\n",
    "    print(f\"   ‚Ä¢ {row['state']}: IFI = {row['ifi']:.1f}\")\n",
    "\n",
    "# At-risk states\n",
    "at_risk_states = state_df[(state_df['ifi'] >= 10) & (state_df['ifi'] < 20)]\n",
    "print(f\"\\nüü° AT-RISK ZONES (IFI 10-20): {len(at_risk_states)} states\")\n",
    "\n",
    "# Healthy states\n",
    "healthy_states = state_df[state_df['ifi'] >= 20]\n",
    "print(f\"\\nüü¢ HEALTHY ZONES (IFI >= 20): {len(healthy_states)} states\")\n",
    "\n",
    "# Population at risk\n",
    "if 'population_2024_est' in state_df.columns:\n",
    "    pop_at_risk = state_df[state_df['ifi'] < 15]['population_2024_est'].sum()\n",
    "    print(f\"\\nüë• ESTIMATED POPULATION AT RISK: {pop_at_risk/1e6:.0f} Million\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
